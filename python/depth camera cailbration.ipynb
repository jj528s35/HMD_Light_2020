{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import roypy\n",
    "import time\n",
    "import queue\n",
    "from sample_camera_info import print_camera_info\n",
    "from roypy_sample_utils import CameraOpener, add_camera_opener_options\n",
    "#from roypy_platform_utils import PlatformHelper\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import os\n",
    "import os.path\n",
    "\n",
    "try:\n",
    "    import roypycy\n",
    "except ImportError:\n",
    "    print(\"Pico Flexx backend requirements (roypycy) not installed properly\")\n",
    "    raise\n",
    "\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyListener(roypy.IDepthDataListener):\n",
    "    def __init__(self, q):\n",
    "        super(MyListener, self).__init__()\n",
    "        self.queue = q\n",
    "\n",
    "    def onNewData(self, data):\n",
    "        grayvalues = []\n",
    "        values = roypycy.get_backend_data(data)\n",
    "        grayvalues = values.grayValue\n",
    "        \n",
    "        p = grayvalues.reshape (-1, data.width)        \n",
    "        self.queue.put(p)\n",
    "            \n",
    "\n",
    "    def paint (self, data):\n",
    "        \"\"\"Called in the main thread, with data containing one of the items that was added to the\n",
    "        queue in onNewData.\n",
    "        \"\"\"\n",
    "        name = \"grayvalues\"\n",
    "        cv2.namedWindow(name, cv2.WINDOW_NORMAL)\n",
    "        cv2.imshow(name, data)\n",
    "        cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grayvalue_scale(img):\n",
    "    grayimg_int8 = cv2.convertScaleAbs(img, alpha=(255.0/65535.0))\n",
    "    scale = 255//grayimg_int8.max()\n",
    "    grayimg = grayimg_int8*scale\n",
    "    return grayimg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def storeimg(img, i):\n",
    "    TARGETDIR = './depth_chessboard_data'\n",
    "    if not os.path.exists(TARGETDIR):\n",
    "        os.mkdir(TARGETDIR)\n",
    "        \n",
    "    cv2.imwrite(TARGETDIR + '/' + str(i).zfill(2) + '.png', img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cailbration_data(image, objpoints, imgpoints, num_of_img):\n",
    "    # prepare object points, like (0,0,0), (1,0,0), (2,0,0) ....,(6,5,0)\n",
    "    # (8,6) is for the given testing images.\n",
    "    # If you use the another data (e.g. pictures you take by your smartphone), \n",
    "    # you need to set the corresponding numbers.\n",
    "    corner_x = 7\n",
    "    corner_y = 7\n",
    "    objp = np.zeros((corner_x*corner_y,3), np.float32)\n",
    "    objp[:,:2] = np.mgrid[0:corner_x, 0:corner_y].T.reshape(-1,2)\n",
    "    \n",
    "    #Find the chessboard corners\n",
    "    ret, corners = cv2.findChessboardCorners(image, (corner_x,corner_y), None)\n",
    "    # If found, add object points, image points\n",
    "    if ret == True:\n",
    "        objpoints.append(objp)\n",
    "        imgpoints.append(corners)\n",
    "\n",
    "        # Draw and display the corners\n",
    "        newImage = image.copy()\n",
    "        cv2.drawChessboardCorners(newImage, (corner_x,corner_y), corners, ret)\n",
    "        \n",
    "        #show image\n",
    "        name = \"Chessboard\"\n",
    "        cv2.namedWindow(name, cv2.WINDOW_NORMAL)\n",
    "        cv2.imshow(name, newImage)\n",
    "        cv2.waitKey(1)\n",
    "        \n",
    "        num_of_img = num_of_img + 1\n",
    "    return objpoints, imgpoints, num_of_img\n",
    "\n",
    "def ceilbration(objpoints, imgpoints, img_size):\n",
    "    print('Camera calibration...')\n",
    "    # You need to comment these functions and write your calibration function from scratch.\n",
    "    # Notice that rvecs is rotation vector, not the rotation matrix, and tvecs is translation vector.\n",
    "    # In practice, you'll derive extrinsics matrixes directly. The shape must be [pts_num,3,4], and use them to plot.\n",
    "    ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, img_size, None,None)\n",
    "    Vr = np.array(rvecs)\n",
    "    Tr = np.array(tvecs)\n",
    "    extrinsics = np.concatenate((Vr, Tr), axis=1).reshape(-1,6)\n",
    "    print('intrinsics mtx :\\n', mtx)\n",
    "    #print('extrinsics :\\n',extrinsics)\n",
    "    #print('Tr :\\n', Tr)\n",
    "    \n",
    "    return mtx, dist, rvecs, tvecs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main ():\n",
    "    parser = argparse.ArgumentParser (usage = __doc__)\n",
    "    add_camera_opener_options (parser)\n",
    "    parser.add_argument (\"--seconds\", type=int, default=15, help=\"duration to capture data\")\n",
    "    #options = parser.parse_args(args=['--rrf', '0108.rrf','--seconds', '5'])\n",
    "    options = parser.parse_args(args=['--seconds', '25'])\n",
    "\n",
    "    opener = CameraOpener (options)\n",
    "    cam = opener.open_camera ()\n",
    "    \n",
    "    Replay = True\n",
    "    if(Replay):\n",
    "        cam.setUseCase('MODE_5_35FPS_600')\n",
    "\n",
    "    print_camera_info (cam)\n",
    "    print(\"isConnected\", cam.isConnected())\n",
    "    print(\"getFrameRate\", cam.getFrameRate())\n",
    "    print(\"UseCase\",cam.getCurrentUseCase())\n",
    "\n",
    "    # we will use this queue to synchronize the callback with the main\n",
    "    # thread, as drawing should happen in the main thread\n",
    "    q = queue.Queue()\n",
    "    l = MyListener(q)\n",
    "    cam.registerDataListener(l)\n",
    "    cam.startCapture()\n",
    "    # create a loop that will run for a time (default 15 seconds)\n",
    "    objpoints, imgpoints, img_size = process_event_queue (q, l, options.seconds)\n",
    "    cam.stopCapture()\n",
    "    \n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "    mtx, dist, rvecs, tvecs = ceilbration(objpoints, imgpoints, img_size)\n",
    "\n",
    "# create a loop that will run for the given amount of time\n",
    "def process_event_queue (q, painter, seconds):\n",
    "    \n",
    "    # Arrays to store object points and image points from all the images.\n",
    "    objpoints = [] # 3d points in real world space\n",
    "    imgpoints = [] # 2d points in image plane.\n",
    "    img_size = (171, 224)\n",
    "    num_of_img = 0\n",
    "    Store = True\n",
    "    \n",
    "    t_end = time.time() + seconds\n",
    "    while time.time() < t_end:\n",
    "        try:\n",
    "            # try to retrieve an item from the queue.\n",
    "            # this will block until an item can be retrieved\n",
    "            # or the timeout of 1 second is hit\n",
    "            grayimg = q.get(True, 1)\n",
    "        except queue.Empty:\n",
    "            # this will be thrown when the timeout is hit\n",
    "            break\n",
    "        else:\n",
    "            grayimg = grayvalue_scale(grayimg)\n",
    "            \n",
    "            #press space and collate data\n",
    "            if cv2.waitKey(10) & 0xFF == ord(' '):\n",
    "                objpoints, imgpoints, num_of_img = cailbration_data(grayimg, objpoints, imgpoints, num_of_img)\n",
    "                if Store:\n",
    "                    storeimg(grayimg, num_of_img)\n",
    "            img_size = (grayimg.shape[1], grayimg.shape[0])\n",
    "            \n",
    "            painter.paint (grayimg)\n",
    "            \n",
    "            if num_of_img >= 7:\n",
    "                break\n",
    "                    \n",
    "    return objpoints, imgpoints, img_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of cameras connected:  1\n",
      "====================================\n",
      "        Camera information\n",
      "====================================\n",
      "Type:            PICOFLEXX\n",
      "Width:           224\n",
      "Height:          171\n",
      "Operation modes: 10\n",
      "    MODE_9_5FPS_2000\n",
      "    MODE_9_10FPS_1000\n",
      "    MODE_9_15FPS_700\n",
      "    MODE_9_25FPS_450\n",
      "    MODE_5_35FPS_600\n",
      "    MODE_5_45FPS_500\n",
      "    MODE_MIXED_30_5\n",
      "        this operation mode has 2 streams\n",
      "    MODE_MIXED_50_5\n",
      "        this operation mode has 2 streams\n",
      "    Low_Noise_Extended\n",
      "    Fast_Acquisition\n",
      "Lens parameters: 9\n",
      "    ('cx', 118.28559112548828)\n",
      "    ('cy', 87.74105072021484)\n",
      "    ('fx', 213.8031768798828)\n",
      "    ('fy', 213.8031768798828)\n",
      "    ('k1', 0.4155448377132416)\n",
      "    ('k2', -4.7316107749938965)\n",
      "    ('k3', 8.45906925201416)\n",
      "    ('p1', 7.605663946304829e-16)\n",
      "    ('p2', 4.939198934392371e-16)\n",
      "CameraInfo items: 8\n",
      "    ('BRIDGE_TYPE', 'Enclustra')\n",
      "    ('MODULE_IDENTIFIER', '00000000')\n",
      "    ('MODULE_IDENTIFIER_HASH', '558161692')\n",
      "    ('MODULE_SERIAL', '0')\n",
      "    ('MODULE_SUFFIX', '')\n",
      "    ('IMAGER', 'M2450_A12_AIO')\n",
      "    ('PROCESSING_NAME', 'Spectre')\n",
      "    ('PROCESSING_VERSION', '4.2.0.897')\n",
      "isConnected True\n",
      "getFrameRate 35\n",
      "UseCase MODE_5_35FPS_600\n",
      "Camera calibration...\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "OpenCV(3.4.2) C:\\projects\\opencv-python\\opencv\\modules\\calib3d\\src\\calibration.cpp:3384: error: (-215:Assertion failed) nimages > 0 in function 'cv::calibrateCamera'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-263240bbee7e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-6-165e5035f786>\u001b[0m in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     30\u001b[0m     \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdestroyAllWindows\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m     \u001b[0mmtx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrvecs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtvecs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mceilbration\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobjpoints\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimgpoints\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     33\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[1;31m# create a loop that will run for the given amount of time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-5-8ccd93e54592>\u001b[0m in \u001b[0;36mceilbration\u001b[1;34m(objpoints, imgpoints, img_size)\u001b[0m\n\u001b[0;32m     34\u001b[0m     \u001b[1;31m# Notice that rvecs is rotation vector, not the rotation matrix, and tvecs is translation vector.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m     \u001b[1;31m# In practice, you'll derive extrinsics matrixes directly. The shape must be [pts_num,3,4], and use them to plot.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 36\u001b[1;33m     \u001b[0mret\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmtx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrvecs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtvecs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcalibrateCamera\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobjpoints\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimgpoints\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     37\u001b[0m     \u001b[0mVr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrvecs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m     \u001b[0mTr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtvecs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(3.4.2) C:\\projects\\opencv-python\\opencv\\modules\\calib3d\\src\\calibration.cpp:3384: error: (-215:Assertion failed) nimages > 0 in function 'cv::calibrateCamera'\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
