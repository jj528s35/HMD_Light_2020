{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import roypy\n",
    "import time\n",
    "import queue\n",
    "from sample_camera_info import print_camera_info\n",
    "from roypy_sample_utils import CameraOpener, add_camera_opener_options\n",
    "#from roypy_platform_utils import PlatformHelper\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import os\n",
    "import os.path\n",
    "\n",
    "try:\n",
    "    import roypycy\n",
    "except ImportError:\n",
    "    print(\"Pico Flexx backend requirements (roypycy) not installed properly\")\n",
    "    raise\n",
    "\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyListener(roypy.IDepthDataListener):\n",
    "    def __init__(self, q):\n",
    "        super(MyListener, self).__init__()\n",
    "        self.queue = q\n",
    "\n",
    "    def onNewData(self, data):\n",
    "        grayvalues = []\n",
    "        values = roypycy.get_backend_data(data)\n",
    "        grayvalues = values.grayValue\n",
    "        \n",
    "        p = grayvalues.reshape (-1, data.width)        \n",
    "        self.queue.put(p)\n",
    "            \n",
    "\n",
    "    def paint (self, name, data):\n",
    "        \"\"\"Called in the main thread, with data containing one of the items that was added to the\n",
    "        queue in onNewData.\n",
    "        \"\"\"\n",
    "        cv2.namedWindow(name, cv2.WINDOW_NORMAL)\n",
    "        cv2.imshow(name, data)\n",
    "        cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grayvalue_scale(img):\n",
    "    grayimg_int8 = cv2.convertScaleAbs(img, alpha=(255.0/65535.0))\n",
    "    scale = 255//grayimg_int8.max()\n",
    "    grayimg = grayimg_int8*scale\n",
    "    return grayimg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def storeimg(img, i):\n",
    "    TARGETDIR = './depth_chessboard_data'\n",
    "    if not os.path.exists(TARGETDIR):\n",
    "        os.mkdir(TARGETDIR)\n",
    "        \n",
    "    cv2.imwrite(TARGETDIR + '/' + str(i).zfill(2) + '.png', img)\n",
    "    \n",
    "def storeRGBimg(img, i):\n",
    "    TARGETDIR = './camera_chessboard_data'\n",
    "    if not os.path.exists(TARGETDIR):\n",
    "        os.mkdir(TARGETDIR)\n",
    "        \n",
    "    cv2.imwrite(TARGETDIR + '/' + str(i).zfill(2) + '.png', img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cailbration_data(image, objpoints, imgpoints, name):\n",
    "    # prepare object points, like (0,0,0), (1,0,0), (2,0,0) ....,(6,5,0)\n",
    "    # (8,6) is for the given testing images.\n",
    "    # If you use the another data (e.g. pictures you take by your smartphone), \n",
    "    # you need to set the corresponding numbers.\n",
    "    corner_x = 8\n",
    "    corner_y = 7\n",
    "    objp = np.zeros((corner_x*corner_y,3), np.float32)\n",
    "    objp[:,:2] = np.mgrid[0:corner_x, 0:corner_y].T.reshape(-1,2)\n",
    "    \n",
    "    #Find the chessboard corners\n",
    "    ret, corners = cv2.findChessboardCorners(image, (corner_x,corner_y), None)\n",
    "    # If found, add object points, image points\n",
    "    if ret == True:\n",
    "        objpoints.append(objp)\n",
    "        imgpoints.append(corners)\n",
    "\n",
    "        # Draw and display the corners\n",
    "        newImage = image.copy()\n",
    "        cv2.drawChessboardCorners(newImage, (corner_x,corner_y), corners, ret)\n",
    "        \n",
    "        #show image\n",
    "        cv2.namedWindow(name, cv2.WINDOW_NORMAL)\n",
    "        cv2.imshow(name, newImage)\n",
    "        cv2.waitKey(1)\n",
    "        \n",
    "    return ret, objpoints, imgpoints\n",
    "\n",
    "def ceilbration(objpoints, imgpoints, img_size):\n",
    "    print('Camera calibration...')\n",
    "    # You need to comment these functions and write your calibration function from scratch.\n",
    "    # Notice that rvecs is rotation vector, not the rotation matrix, and tvecs is translation vector.\n",
    "    # In practice, you'll derive extrinsics matrixes directly. The shape must be [pts_num,3,4], and use them to plot.\n",
    "    ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, img_size, None,None)\n",
    "    Vr = np.array(rvecs)\n",
    "    Tr = np.array(tvecs)\n",
    "    extrinsics = np.concatenate((Vr, Tr), axis=1).reshape(-1,6)\n",
    "    print('intrinsics mtx :\\n', mtx)\n",
    "    #print('extrinsics :\\n',extrinsics)\n",
    "    #print('Tr :\\n', Tr)\n",
    "    \n",
    "    return mtx, dist, rvecs, tvecs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main ():\n",
    "    parser = argparse.ArgumentParser (usage = __doc__)\n",
    "    add_camera_opener_options (parser)\n",
    "    parser.add_argument (\"--seconds\", type=int, default=15, help=\"duration to capture data\")\n",
    "    #options = parser.parse_args(args=['--rrf', '0108.rrf','--seconds', '5'])\n",
    "    options = parser.parse_args(args=['--seconds', '500'])\n",
    "\n",
    "    opener = CameraOpener (options)\n",
    "    cam = opener.open_camera ()\n",
    "    \n",
    "    Replay = True\n",
    "    if(Replay):\n",
    "        cam.setUseCase('MODE_5_35FPS_600')\n",
    "\n",
    "    print_camera_info (cam)\n",
    "    print(\"isConnected\", cam.isConnected())\n",
    "    print(\"getFrameRate\", cam.getFrameRate())\n",
    "    print(\"UseCase\",cam.getCurrentUseCase())\n",
    "\n",
    "    # we will use this queue to synchronize the callback with the main\n",
    "    # thread, as drawing should happen in the main thread\n",
    "    q = queue.LifoQueue()\n",
    "    l = MyListener(q)\n",
    "    cam.registerDataListener(l)\n",
    "    cam.startCapture()\n",
    "    # create a loop that will run for a time (default 15 seconds)\n",
    "    objpoints, imgpoints, img_size = process_event_queue (q, l, options.seconds)\n",
    "    cam.stopCapture()\n",
    "    \n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "    mtx, dist, rvecs, tvecs = ceilbration(objpoints, imgpoints, img_size)\n",
    "\n",
    "# create a loop that will run for the given amount of time\n",
    "def process_event_queue (q, painter, seconds):\n",
    "    \n",
    "    # Arrays to store object points and image points from all the images.\n",
    "    objpoints = [] # 3d points in real world space\n",
    "    imgpoints = [] # 2d points in image plane.\n",
    "    img_size = (171, 224)\n",
    "    num_of_img = 0\n",
    "    Store = True\n",
    "    Both = True\n",
    "    \n",
    "    t_end = time.time() + seconds\n",
    "    \n",
    "    if Both :\n",
    "        RGB_objpoints = [] # 3d points in real world space\n",
    "        RGB_imgpoints = [] # 2d points in image plane.\n",
    "        capture = cv2.VideoCapture(0)\n",
    "        capture.open(1 + cv2.CAP_DSHOW)\n",
    "        capture.set(3, 1280) # set the resolution\n",
    "        capture.set(4, 720)\n",
    "        capture.set(cv2.CAP_PROP_AUTOFOCUS, 0) # turn the autofocus off  #0204 尚未測試\n",
    "    else:\n",
    "        RGB_ret = True\n",
    "\n",
    "    while time.time() < t_end:\n",
    "        try:\n",
    "            # try to retrieve an item from the queue.\n",
    "            # this will block until an item can be retrieved\n",
    "            # or the timeout of 1 second is hit\n",
    "            grayimg = q.get(True, 1)\n",
    "            \n",
    "#             ret, frame = capture.read()\n",
    "#             gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        except queue.Empty:\n",
    "            # this will be thrown when the timeout is hit\n",
    "            break\n",
    "        else:\n",
    "#             grayimg = grayvalue_scale(grayimg)\n",
    "            grayimg = cv2.convertScaleAbs(grayimg)\n",
    "            \n",
    "            #press space and collate data\n",
    "            if cv2.waitKey(10) & 0xFF == ord(' '):\n",
    "                ret, objpoints, imgpoints = cailbration_data(grayimg, objpoints, imgpoints, 'Chessboard')\n",
    "                if Both :\n",
    "                    ret, frame = capture.read()\n",
    "                    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "                    RGB_ret, RGB_objpoints, RGB_imgpoints = cailbration_data(gray, RGB_objpoints, RGB_imgpoints, 'RGB_Chessboard')\n",
    "                if Store and ret and RGB_ret:\n",
    "                    num_of_img = num_of_img + 1\n",
    "                    storeimg(grayimg, num_of_img)\n",
    "                    if Both :\n",
    "                        storeRGBimg(frame, num_of_img)\n",
    "            img_size = (grayimg.shape[1], grayimg.shape[0])\n",
    "            \n",
    "            painter.paint ('grayvalues',grayimg)\n",
    "#             painter.paint ('gray',gray)\n",
    "            \n",
    "            if num_of_img >= 5 or cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "                break\n",
    "                    \n",
    "    return objpoints, imgpoints, img_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of cameras connected:  1\n",
      "====================================\n",
      "        Camera information\n",
      "====================================\n",
      "Type:            PICOFLEXX\n",
      "Width:           224\n",
      "Height:          171\n",
      "Operation modes: 10\n",
      "    MODE_9_5FPS_2000\n",
      "    MODE_9_10FPS_1000\n",
      "    MODE_9_15FPS_700\n",
      "    MODE_9_25FPS_450\n",
      "    MODE_5_35FPS_600\n",
      "    MODE_5_45FPS_500\n",
      "    MODE_MIXED_30_5\n",
      "        this operation mode has 2 streams\n",
      "    MODE_MIXED_50_5\n",
      "        this operation mode has 2 streams\n",
      "    Low_Noise_Extended\n",
      "    Fast_Acquisition\n",
      "Lens parameters: 9\n",
      "    ('cx', 118.28559112548828)\n",
      "    ('cy', 87.74105072021484)\n",
      "    ('fx', 213.8031768798828)\n",
      "    ('fy', 213.8031768798828)\n",
      "    ('k1', 0.4155448377132416)\n",
      "    ('k2', -4.7316107749938965)\n",
      "    ('k3', 8.45906925201416)\n",
      "    ('p1', 7.605663946304829e-16)\n",
      "    ('p2', 4.939198934392371e-16)\n",
      "CameraInfo items: 8\n",
      "    ('BRIDGE_TYPE', 'Enclustra')\n",
      "    ('MODULE_IDENTIFIER', '00000000')\n",
      "    ('MODULE_IDENTIFIER_HASH', '558161692')\n",
      "    ('MODULE_SERIAL', '0')\n",
      "    ('MODULE_SUFFIX', '')\n",
      "    ('IMAGER', 'M2450_A12_AIO')\n",
      "    ('PROCESSING_NAME', 'Spectre')\n",
      "    ('PROCESSING_VERSION', '4.2.0.897')\n",
      "isConnected True\n",
      "getFrameRate 35\n",
      "UseCase MODE_5_35FPS_600\n",
      "Camera calibration...\n",
      "intrinsics mtx :\n",
      " [[213.21284577   0.         113.33190842]\n",
      " [  0.         213.35737631  84.57316738]\n",
      " [  0.           0.           1.        ]]\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
