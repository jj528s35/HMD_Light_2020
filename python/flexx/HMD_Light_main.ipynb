{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import roypy\n",
    "import time\n",
    "import queue\n",
    "from sample_camera_info import print_camera_info\n",
    "from roypy_sample_utils import CameraOpener, add_camera_opener_options\n",
    "#from roypy_platform_utils import PlatformHelper\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import random\n",
    "import math\n",
    "import socket_sender\n",
    "from matplotlib.path import Path\n",
    "\n",
    "\n",
    "try:\n",
    "    import roypycy\n",
    "except ImportError:\n",
    "    print(\"Pico Flexx backend requirements (roypycy) not installed properly\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RANSAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # RANSAM\n",
    "\n",
    "def Dis_pt2plane(pts, a, b, c, d):\n",
    "    \"\"\"\n",
    "    Compute the distance from points to the plane\n",
    "    \"\"\"\n",
    "    normal = math.sqrt(a*a+b*b+c*c)\n",
    "    if normal == 0:\n",
    "        normal = 1\n",
    "    \n",
    "    v = np.array([a,b,c])\n",
    "    dis = abs(np.dot(pts,v.T)+d)/normal\n",
    "    return dis\n",
    "\n",
    "def get_Plane(sampts):\n",
    "    \"\"\"\n",
    "    Compute the equation of the plane\n",
    "    \"\"\"\n",
    "    p1 = sampts[0]\n",
    "    p2 = sampts[1]\n",
    "    p3 = sampts[2]\n",
    "    \n",
    "    a = ( (p2[1]-p1[1])*(p3[2]-p1[2])-(p2[2]-p1[2])*(p3[1]-p1[1]) )\n",
    "    b = ( (p2[2]-p1[2])*(p3[0]-p1[0])-(p2[0]-p1[0])*(p3[2]-p1[2]) )\n",
    "    c = ( (p2[0]-p1[0])*(p3[1]-p1[1])-(p2[1]-p1[1])*(p3[0]-p1[0]) )\n",
    "    d = ( 0-(a*p1[0]+b*p1[1]+c*p1[2]) )\n",
    "    \n",
    "    return a,b,c,d\n",
    "\n",
    "# def Random3points(points3D, ConfidenceIndex):\n",
    "#     \"\"\"\n",
    "#     Random choose 3 Confidence points\n",
    "#     \"\"\"\n",
    "#     sample_number = 3\n",
    "#     sample_point_index = random.sample(range(ConfidenceIndex.shape[0]), sample_number)\n",
    "#     sample_points = np.zeros((sample_number,3))\n",
    "#     for i in range(sample_number):\n",
    "#         Confidence_point_index = sample_point_index[i]\n",
    "#         index = ConfidenceIndex[Confidence_point_index]\n",
    "#         y = index // points3D.shape[1]\n",
    "#         x = index % points3D.shape[1]\n",
    "#         sample_points[i] = points3D[y][x]\n",
    "#     return sample_points\n",
    "\n",
    "def Random3points(points3D):\n",
    "    sample_number = 30\n",
    "    sample_point_index = random.sample(range(points3D.shape[0]*points3D.shape[1]), sample_number)\n",
    "    sample_points = np.zeros((3,3))\n",
    "    num = 0\n",
    "    for i in range(sample_number):\n",
    "        index = sample_point_index[i]\n",
    "        y = index // points3D.shape[1]\n",
    "        x = index % points3D.shape[1]\n",
    "        \n",
    "        point = points3D[y][x]\n",
    "        if(point[0] != 0 or point[1] != 0 or point[2] != 0):\n",
    "            sample_points[num] = points3D[y][x]\n",
    "            num = num + 1\n",
    "        \n",
    "        if(num == 3):\n",
    "            break\n",
    "    return sample_points\n",
    "\n",
    "def get_inliner_num(points3D,a,b,c,d,inliner_threshold,Confidence_img):\n",
    "    \"\"\"\n",
    "    Compute the liner points which distance to plane < threshold\n",
    "    Also get distance from points to the plane (new Depth Image which re-project depth pixels in surface plane)\n",
    "    \"\"\"\n",
    "    inliner_num = 0\n",
    "    \n",
    "    dist = Dis_pt2plane(points3D,a,b,c,d)\n",
    "    inliner_mask = dist < inliner_threshold\n",
    "    inliner_mask = np.logical_and(inliner_mask, Confidence_img)\n",
    "    inliner_num = np.sum(inliner_mask)\n",
    "    return inliner_num, inliner_mask, dist\n",
    "\n",
    "def RANSAM(points3D, Confidence_img, ransac_iteration = 1000, inliner_threshold = 0.01):\n",
    "    best_inlinernum = -1\n",
    "    best_inlinernum = 0\n",
    "    best_plane = np.zeros((1,4))\n",
    "    best_depthImage = np.zeros((points3D.shape[0],points3D.shape[1]))\n",
    "    best_plane_mask = np.zeros((points3D.shape[0],points3D.shape[1]))\n",
    "    best_sampts = np.zeros((3,3))\n",
    "    \n",
    "#     print(points3D.shape,points3D[80:90,110])\n",
    "    for i in range(ransac_iteration):\n",
    "        sampts = Random3points(points3D)\n",
    "        a,b,c,d = get_Plane(sampts)\n",
    "        \n",
    "        inliner_num, inliner_mask, depthImage = get_inliner_num(points3D,a,b,c,d,inliner_threshold,Confidence_img)\n",
    "        if(inliner_num > best_inlinernum):\n",
    "            best_inlinernum = inliner_num\n",
    "            best_plane = np.array([a,b,c,d])\n",
    "            best_plane_mask = inliner_mask\n",
    "            best_depthImage = depthImage\n",
    "            best_sampts = sampts\n",
    "            \n",
    "    #print(\"Inliner Number\\n\", best_inlinernum)\n",
    "    #print(\"Inliner plane\\n\", best_plane)\n",
    "    return best_plane, best_depthImage, best_plane_mask, best_sampts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_target_ellipse(img, quad_mask):\n",
    "    ret = False\n",
    "    px = 0\n",
    "    py = 0\n",
    "    mask = quad_mask.astype(np.uint8)*255\n",
    "    circles_image = cv2.add(img, np.zeros(np.shape(img), dtype=np.uint8), mask=mask)\n",
    "    \n",
    "    # Set up the detector with default parameters.\n",
    "    detector = cv2.SimpleBlobDetector_create()\n",
    "\n",
    "    # Detect blobs.\n",
    "    keypoints = detector.detect(circles_image)\n",
    "\n",
    "    if len(keypoints) > 0:\n",
    "        ret = True\n",
    "        circles_image = cv2.cvtColor(circles_image, cv2.COLOR_GRAY2BGR)\n",
    "        circles_image = cv2.drawKeypoints(circles_image, keypoints, np.array([]), (0,255,0), cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "        px = int(keypoints[-1].pt[0])\n",
    "        py = int(keypoints[-1].pt[1])\n",
    "        cv2.circle(circles_image, (px,py), 2, (0,0,225), 2)\n",
    "\n",
    "    \n",
    "    return ret, px, py, circles_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Draw 3D plane"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "def show_plane(plane_eq):\n",
    "    a,b,c,d = plane_eq[0], plane_eq[1], plane_eq[2], plane_eq[3]\n",
    "    x = np.linspace(-1,1,10)\n",
    "    y = np.linspace(-1,1,10)\n",
    "\n",
    "    X,Y = np.meshgrid(x,y)\n",
    "    Z = (d - a*X - b*Y) / c\n",
    "\n",
    "    fig = plt.figure()\n",
    "    ax = fig.gca(projection='3d')\n",
    "\n",
    "    surf = ax.plot_surface(X, Y, Z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tranform Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def send_plane_eq(plane_eq):\n",
    "    data = \"\"\n",
    "    temp1 = ['1 ']\n",
    "    temp1.append(\"%f %f %f %f\"%(plane_eq[0], plane_eq[1], plane_eq[2], plane_eq[3]))\n",
    "    data = data.join(temp1)\n",
    "#     print('send plane_eq:', data)\n",
    "    socket_sender.send(data)\n",
    "    \n",
    "def send_sample_points(sample_points):\n",
    "    data = \"\"\n",
    "    temp2 = ['2 ']\n",
    "    for i in range(3): \n",
    "        temp2.append(\"%f %f %f \"%(sample_points[i][0], sample_points[i][1], sample_points[i][2]))\n",
    "    data = data.join(temp2)\n",
    "#     print('send sample point:', data)\n",
    "    socket_sender.send(data)\n",
    "    \n",
    "\n",
    "# def send_plane_points(points, points_3d, plane_mask, cx, cy):\n",
    "#     data = \"\"\n",
    "#     temp3 = ['3 ']\n",
    "#     point_num = len(points)\n",
    "#     temp3.append(\"%d \"%(point_num))\n",
    "#     for i in range(point_num): \n",
    "#         x = points[i,0,0]\n",
    "#         y = points[i,0,1]\n",
    "#         if(plane_mask[y,x] == False):\n",
    "#             x, y = find_points_on_plane(y, x, plane_mask, kernel_size = 15)\n",
    "#         #if there is still not on the plane than find the point at the center of cx and x\n",
    "#         if(plane_mask[y,x] == False):\n",
    "#             i = 40\n",
    "#             while i>0:\n",
    "#                 if(plane_mask[y,x] == False):\n",
    "#                     y1 = y + (cy - y)//i\n",
    "#                     x1 = x + (cx - x)//i\n",
    "#                     x, y = find_points_on_plane(y1, x1, plane_mask, kernel_size = 15)\n",
    "#                     i = i-1\n",
    "#                 else:\n",
    "#                     print(i+1)\n",
    "#                     break\n",
    "#         temp3.append(\"%f %f %f \"%(points_3d[y,x,0], points_3d[y,x,1], points_3d[y,x,2]))\n",
    "#     data = data.join(temp3)\n",
    "# #     print('send plane point:', data)\n",
    "#     socket_sender.send(data)\n",
    "    \n",
    "def send_plane_points(points):\n",
    "    data = \"\"\n",
    "    temp3 = ['3 ']\n",
    "    point_num = len(points)\n",
    "    temp3.append(\"%d \"%(point_num))\n",
    "    for i in range(point_num): \n",
    "        x = points[i,0]\n",
    "        y = points[i,1]\n",
    "        z = points[i,2]\n",
    "        temp3.append(\"%f %f %f \"%(x, y, z))\n",
    "        if i == 3:\n",
    "            break\n",
    "    data = data.join(temp3)\n",
    "#     print('send plane point:', data)\n",
    "    if point_num > 4:\n",
    "        print(\"more than 4 points\")\n",
    "    socket_sender.send(data)\n",
    "    \n",
    "def send_plane_center(x, y, points_3d):\n",
    "    data = \"\"\n",
    "    temp4 = ['4 ']\n",
    "    temp4.append(\"%f %f %f\"%(points_3d[y,x,0], points_3d[y,x,1], points_3d[y,x,2]))\n",
    "    data = data.join(temp4)\n",
    "#     print('send plane point:', data)\n",
    "    socket_sender.send(data)\n",
    "\n",
    "def send_targetpos(x, y, points_3d):\n",
    "    data = \"\"\n",
    "    temp4 = ['5 ']\n",
    "    temp4.append(\"%f %f %f\"%(points_3d[y,x,0], points_3d[y,x,1], points_3d[y,x,2]))\n",
    "    data = data.join(temp4)\n",
    "#     print('send plane point:', data)\n",
    "    socket_sender.send(data)\n",
    "    \n",
    "def receive_data(cam):\n",
    "    data = socket_sender.receive()\n",
    "    if(data != None):\n",
    "        print(\"receive \" + data)\n",
    "        ParseData(data, cam)\n",
    "        \n",
    "def ParseData(data, cam):\n",
    "    # split the string at ' '\n",
    "    msg = data.split(' ')\n",
    "    # get the first slice of the list\n",
    "    data_type = int(msg[0])\n",
    "    \n",
    "    if(data_type == 1):# change user case\n",
    "        fps = int(msg[1])\n",
    "        change_user_case(fps,cam)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_user_case(fps,cam):\n",
    "    if(fps == 5):\n",
    "        cam.setUseCase('MODE_9_5FPS_2000')\n",
    "    print(\"UseCase\",cam.getCurrentUseCase())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# find quadrilateral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def edge(plane_mask):\n",
    "#     low_threshold = 2\n",
    "#     high_threshold = 10\n",
    "\n",
    "#     plane_blur = MorphologyEx(plane_mask)\n",
    "#     Cannyedges = cv2.Canny(plane_blur, low_threshold, high_threshold)#blur_gray\n",
    "#     return Cannyedges\n",
    "\n",
    "\n",
    "\n",
    "# def HoughLines(img):\n",
    "#     HoughLines_edge = np.zeros((img.shape[0],img.shape[1]))\n",
    "\n",
    "#     plane_blur = MorphologyEx(img)\n",
    "#     edges = cv2.Canny(plane_blur,2,10)\n",
    "\n",
    "#     P = False\n",
    "#     if(P):\n",
    "#         #hough transform\n",
    "#         lines = cv2.HoughLinesP(edges,1,np.pi/180,30,minLineLength=40,maxLineGap=50)\n",
    "#         if lines is not None:\n",
    "#             lines1 = lines[:,0,:]#提取为二维\n",
    "#             for x1,y1,x2,y2 in lines1[:]: \n",
    "#                 cv2.line(HoughLines_edge,(x1,y1),(x2,y2),255,2)\n",
    "#     else:\n",
    "# #     hough transform\n",
    "#         lines = cv2.HoughLines(edges,1,np.pi/180,50)\n",
    "#         if lines is not None:\n",
    "#             lines1 = lines[:,0,:]#提取为为二维\n",
    "#             for rho,theta in lines1[:]: \n",
    "#                 a = np.cos(theta)\n",
    "#                 b = np.sin(theta)\n",
    "#                 x0 = a*rho\n",
    "#                 y0 = b*rho\n",
    "#                 x1 = int(x0 + 1000*(-b))\n",
    "#                 y1 = int(y0 + 1000*(a))\n",
    "#                 x2 = int(x0 - 1000*(-b))\n",
    "#                 y2 = int(y0 - 1000*(a)) \n",
    "#                 cv2.line(HoughLines_edge,(x1,y1),(x2,y2),255,2)\n",
    "\n",
    "#     return HoughLines_edge\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MorphologyEx(img):\n",
    "    kernel_size = 5 #7\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT,(kernel_size, kernel_size))\n",
    "    #膨胀之后再腐蚀，在用来关闭前景对象里的小洞或小黑点\n",
    "    #开运算用于移除由图像噪音形成的斑点\n",
    "    opened = cv2.morphologyEx(img, cv2.MORPH_OPEN, kernel)\n",
    "    closing = cv2.morphologyEx(img,cv2.MORPH_CLOSE,kernel)\n",
    "    \n",
    "    kernel_size = 3\n",
    "    plane_blur = cv2.GaussianBlur(closing,(kernel_size, kernel_size), 0)\n",
    "    return plane_blur\n",
    "\n",
    "\n",
    "def find_quadrilateral(img):\n",
    "    HoughLines_edge = np.zeros((img.shape[0],img.shape[1]))\n",
    "    cx = 0\n",
    "    cy = 0\n",
    "    approx = []\n",
    "    ret = False\n",
    "    \n",
    "    #关闭前景对象里的小洞或小黑点\n",
    "    blur = MorphologyEx(img)\n",
    "    image = cv2.cvtColor(blur, cv2.COLOR_GRAY2BGR)\n",
    "    \n",
    "    #find Contours with large area\n",
    "    (_, cnts, _) = cv2.findContours(blur, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    cnts=sorted(cnts, key = cv2.contourArea, reverse = True)[:5]\n",
    "\n",
    "    # loop over our contours\n",
    "    for c in cnts:\n",
    "        peri = cv2.arcLength(c, True)#輪廓長度\n",
    "        area = cv2.contourArea(c)\n",
    "        \n",
    "        approx = cv2.approxPolyDP(c, 0.08 * peri, True)#把一个连续光滑曲线折线化\n",
    "        approx = cv2.convexHull(approx)# find凸多邊形框\n",
    "        if area > 500:\n",
    "            approx = cv2.approxPolyDP(c, 0.08 * peri, True)#把一个连续光滑曲线折线化\n",
    "            approx = cv2.convexHull(approx)# find凸多邊形框\n",
    "            if len(approx) == 4 :\n",
    "                cv2.drawContours(image, [approx], -1, (255,0,0), 3)\n",
    "                break\n",
    "            elif len(approx) > 4:\n",
    "                k = 0.09\n",
    "                while k < 0.2 and len(approx) > 4:\n",
    "                    approx = cv2.approxPolyDP(c, k * peri, True)\n",
    "                    approx = cv2.convexHull(approx)#find凸多邊形框\n",
    "                    k = k + 0.03\n",
    "                    if len(approx) == 4 :\n",
    "                        cv2.drawContours(image, [approx], -1, (0,0,255), 3)\n",
    "                        break\n",
    "            elif len(approx) < 4:\n",
    "                k = 0.07\n",
    "                while k > 0.02 and len(approx) < 4:\n",
    "                    approx = cv2.approxPolyDP(c, k * peri, True)\n",
    "                    approx = cv2.convexHull(approx)#find凸多邊形框\n",
    "                    k = k - 0.02\n",
    "                    if len(approx) == 4 :\n",
    "                        cv2.drawContours(image, [approx], -1, (0,0,255), 3)\n",
    "                        break\n",
    "\n",
    "        if len(approx) == 4 :\n",
    "            ret = True\n",
    "            break\n",
    "    \n",
    "    if(len(approx)):\n",
    "        M = cv2.moments(approx)\n",
    "        if (M['m00'] != 0):\n",
    "            cx = int(M['m10']/M['m00'])\n",
    "            cy = int(M['m01']/M['m00'])\n",
    "            cv2.circle(image, (cx,cy), 3, (0, 255, 255), -1)\n",
    "        if cy >= img.shape[0] or cx >= img.shape[1] or cx < 0 or cy < 0:\n",
    "            cx,cy = 0,0\n",
    "        \n",
    "    if len(approx) >= 4 :\n",
    "        ret = True\n",
    "    \n",
    "    return ret, image, approx, cx, cy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_quad_mask(new_approx, shape):\n",
    "    height = shape[0]\n",
    "    width = shape[1]\n",
    "    mask = np.ones((height,width))\n",
    "    polygon = []\n",
    "    \n",
    "    if (len(new_approx) >= 4):\n",
    "        polygon=[(new_approx[0,0,1],new_approx[0,0,0]), (new_approx[1,0,1],new_approx[1,0,0]), (new_approx[2,0,1],new_approx[2,0,0]), (new_approx[3,0,1],new_approx[3,0,0])]\n",
    "    elif (len(new_approx) == 3):\n",
    "        polygon=[(new_approx[0,0,1],new_approx[0,0,0]), (new_approx[1,0,1],new_approx[1,0,0]), (new_approx[2,0,1],new_approx[2,0,0])]\n",
    "\n",
    "    if (len(new_approx) >= 3 ):\n",
    "        successful = True\n",
    "        poly_path=Path(polygon)\n",
    "\n",
    "        x, y = np.mgrid[:height, :width]\n",
    "        coors=np.hstack((x.reshape(-1, 1), y.reshape(-1,1))) # coors.shape is (4000000,2)\n",
    "\n",
    "        mask = poly_path.contains_points(coors)\n",
    "        mask = mask.reshape(height, width)\n",
    "    else:\n",
    "        successful = False\n",
    "    return successful, mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find point with depth value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_points_on_plane(y, x, mask, kernel_size):\n",
    "    k = kernel_size//2\n",
    "    for cy in range(y-k,y+k+1):\n",
    "        for cx in range(x-k,x+k+1):\n",
    "            if cx >= 0 and cy >=0 and cx < mask.shape[1] and cy < mask.shape[0] and mask[cy,cx] == True:\n",
    "                break\n",
    "                return cx, cy\n",
    "    \n",
    "    #if no on the plane ==> 放大kernel size\n",
    "    kernel_size = kernel_size*2 -1\n",
    "    k = kernel_size//2\n",
    "    for cy in range(y-k,y+k+1):\n",
    "        for cx in range(x-k,x+k+1):\n",
    "            if cx >= 0 and cy >=0 and cx < mask.shape[1] and cy < mask.shape[0] and mask[cy,cx] == True:\n",
    "                break\n",
    "                return cx, cy\n",
    "    return x, y\n",
    "\n",
    "\n",
    "def find_plane_points_with_depth_value(points, plane_mask, points_3d, cx, cy):\n",
    "    point_num = len(points)\n",
    "    z_points = np.zeros((point_num,3))\n",
    "    for i in range(point_num): \n",
    "        x = points[i,0,0]\n",
    "        y = points[i,0,1]\n",
    "        if(plane_mask[y,x] == False):\n",
    "            x, y = find_points_on_plane(y, x, plane_mask, kernel_size = 15)\n",
    "        #if there is still not on the plane than find the point at the center of cx and x\n",
    "        if(plane_mask[y,x] == False):\n",
    "            k = 40\n",
    "            while k>0:\n",
    "                if(plane_mask[y,x] == False):\n",
    "                    y1 = y + (cy - y)//k\n",
    "                    x1 = x + (cx - x)//k\n",
    "                    x, y = find_points_on_plane(y1, x1, plane_mask, kernel_size = 15)\n",
    "                    k = k-1\n",
    "                else:\n",
    "#                     print(k+1)\n",
    "                    break\n",
    "        z_points[i,0] = points_3d[y,x,0]\n",
    "        z_points[i,1] = points_3d[y,x,1]\n",
    "        z_points[i,2] = points_3d[y,x,2]\n",
    "        \n",
    "        points[i,0,0] = x\n",
    "        points[i,0,1] = y\n",
    "        \n",
    "    return z_points, points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_reasonable_value_of_center_vertices(cx, cy, plane_mask, approx, points3D, find_quad_img, kernel_size = 7):\n",
    "    #check if the center is on the plane(for get the reasonable vale of 3d_point)\n",
    "    #if not ==> check the point nearby the center\n",
    "    if(plane_mask[cy,cx] == False):\n",
    "        cx, cy = find_points_on_plane(cy, cx, plane_mask, kernel_size = 7)\n",
    "\n",
    "    #check if the plane points is on the plane(for get the reasonable vale of 3d_point)\n",
    "    #points_z : 3d points , new_approx : 2d points\n",
    "    points_z, new_approx = find_plane_points_with_depth_value(approx, plane_mask, points3D, cx, cy)\n",
    "    cv2.drawContours(find_quad_img, [new_approx], -1, (0,255,255), 3)\n",
    "    \n",
    "    return cx, cy, points_z, new_approx, find_quad_img \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# feet_detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def feet_detection(depthImg, quad_mask, height = 0.05, feet_height = 0.1):\n",
    "#     highter_region = depthImg > height\n",
    "#     lower_region = depthImg < feet_height\n",
    "#     feet_region = np.logical_and(highter_region, lower_region)\n",
    "#     Confidence_feet_region = np.logical_and(feet_region, quad_mask)\n",
    "    \n",
    "#     return MorphologyEx(Confidence_feet_region.astype(np.uint8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feet_detection2(depthImg, mask_successful, quad_mask, height = 0.05, feet_height = 0.1):\n",
    "    #find the highter_region mask which distance between resulting plane is > height\n",
    "    #Then find the highter_region_in_quad : the higher region which is inside the quad mask\n",
    "    highter_region = depthImg > height\n",
    "    if (mask_successful):\n",
    "        highter_region_in_quad = np.logical_and(highter_region, quad_mask)\n",
    "    else:\n",
    "        highter_region_in_quad = highter_region\n",
    "        ellipse_list = []\n",
    "        feet_region_with_Ellipses = np.zeros(depthImg.shape)\n",
    "        return feet_region_with_Ellipses, ellipse_list\n",
    "    \n",
    "    #find the mask of the max contourArea in highter_region_in_quad ==> find the body, leg, and feet\n",
    "    area = 0\n",
    "    max_highter_region = np.zeros(depthImg.shape)\n",
    "    (_, cnts, _) = cv2.findContours(highter_region_in_quad.astype(np.uint8)*255, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE) \n",
    "    if len(cnts) >= 1 :\n",
    "        cnts = sorted(cnts, key = cv2.contourArea, reverse = True)[:2]\n",
    "        for c in cnts:\n",
    "            area = cv2.contourArea(c)\n",
    "            if area > 1000: #the body, leg, and feet area > 1000\n",
    "                #依Contours圖形建立mask\n",
    "                cv2.drawContours(max_highter_region, [c], -1, True, -1) #255        →白色, -1→塗滿\n",
    "        \n",
    "    \n",
    "    #find the lower_region mask which distance between resulting plane is < feet_height\n",
    "    #feet_region : max_highter_region which distance between resulting plane is < feet_height\n",
    "    lower_region = depthImg < feet_height\n",
    "    feet_region = np.logical_and(max_highter_region, lower_region)\n",
    "    \n",
    "    feet_region_smooth = MorphologyEx(feet_region.astype(np.uint8))\n",
    "    \n",
    "    feet_region_with_Ellipses, ellipse_list = fit_Ellipses(feet_region_smooth)\n",
    "    \n",
    "    return feet_region_with_Ellipses, ellipse_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_Ellipses(feet_region):\n",
    "    image = cv2.cvtColor(feet_region.astype(np.uint8)*255, cv2.COLOR_GRAY2BGR)\n",
    "    ellipse_List = []\n",
    "    (_, cnts, _) = cv2.findContours(feet_region, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    cnts = sorted(cnts, key = cv2.contourArea, reverse = True)[:2]\n",
    "    \n",
    "    # loop over our contours\n",
    "    for c in cnts:\n",
    "        area = cv2.contourArea(c)\n",
    "        if area > 50 and len(c) >= 5:\n",
    "            ellipse = cv2.fitEllipse(c)\n",
    "            Area = Ellipse_area(ellipse[1][0], ellipse[1][1])\n",
    "            if Area > 50 and Area < 1600 and area/Area > 0.7:\n",
    "                ellipse_List.append(cv2.fitEllipse(c))\n",
    "                cv2.ellipse(image, ellipse, (0,255,255), 2)\n",
    "\n",
    "    return image, ellipse_List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Ellipse_area(a2, b2):\n",
    "    a = a2 / 2\n",
    "    b = b2 / 2\n",
    "    Area = 3.142 * a * b \n",
    "    \n",
    "    #長寬比\n",
    "    if( a > b*3):\n",
    "        return 0\n",
    "\n",
    "    return Area \n",
    "\n",
    "\n",
    "def find_foci(image, ellipse_List):\n",
    "    for ellipse in ellipse_List:\n",
    "        a = ellipse[1][0] / 2\n",
    "        b = ellipse[1][1] / 2\n",
    "        c = np.sqrt(np.power(a,2) - np.power(b,2))\n",
    "        \n",
    "        x = ellipse[0][0] + c * np.cos(ellipse[2])\n",
    "        y = ellipse[0][1] + c * np.sin(ellipse[2])\n",
    "        cv2.circle(image, (x,y), 5 , (255,255,0) , 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def showimg_by_plt(data):\n",
    "    # create a figure and show the raw data\n",
    "    plt.figure(1)\n",
    "    plt.imshow(data)\n",
    "\n",
    "    plt.show(block = False)\n",
    "    plt.draw()\n",
    "    # this pause is needed to ensure the drawing for\n",
    "    # some backends\n",
    "    plt.pause(0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class MyListener(roypy.IDepthDataListener):\n",
    "    def __init__(self, xqueue, yqueue, zqueue, grayValuequeue):\n",
    "        super(MyListener, self).__init__()\n",
    "        self.xqueue = xqueue\n",
    "        self.yqueue = yqueue\n",
    "        self.zqueue = zqueue\n",
    "        self.grayValuequeue = grayValuequeue\n",
    "        self.Listening = True\n",
    "\n",
    "    def onNewData(self, data):   \n",
    "        if(self.Listening):\n",
    "            t_time = time.time()\n",
    "            \n",
    "            xvalues = []\n",
    "            yvalues = []\n",
    "            zvalues = []\n",
    "            grayvalues = []\n",
    "            \n",
    "            values = roypycy.get_backend_data(data)\n",
    "\n",
    "            xvalues = values.x\n",
    "            yvalues = values.y\n",
    "            zvalues = values.z\n",
    "            grayvalues = values.grayValue\n",
    "\n",
    "            xarray = np.asarray(xvalues)\n",
    "            yarray = np.asarray(yvalues)\n",
    "            zarray = np.asarray(zvalues)\n",
    "            \n",
    "            \n",
    "            q_x = xarray.reshape (-1, data.width)        \n",
    "            self.xqueue.put(q_x)\n",
    "            q_y = yarray.reshape (-1, data.width)        \n",
    "            self.yqueue.put(q_y)\n",
    "            q_z = zarray.reshape (-1, data.width)        \n",
    "            self.zqueue.put(q_z)\n",
    "            \n",
    "            q_grayvalues = grayvalues.reshape (-1, data.width)        \n",
    "            self.grayValuequeue.put(q_grayvalues)\n",
    "            \n",
    "            #print('store time:', (time.time()-t_time))\n",
    "\n",
    "    def paint (self, data, name):\n",
    "        \"\"\"Called in the main thread, with data containing one of the items that was added to the\n",
    "        queue in onNewData.\n",
    "        \"\"\"\n",
    "        cv2.namedWindow(name, cv2.WINDOW_NORMAL)\n",
    "        cv2.imshow(name, data)\n",
    "        cv2.waitKey(1)\n",
    "\n",
    "\n",
    "def main ():\n",
    "    parser = argparse.ArgumentParser (usage = __doc__)\n",
    "    add_camera_opener_options (parser)\n",
    "    parser.add_argument (\"--seconds\", type=int, default=15, help=\"duration to capture data\")\n",
    "    timer_show = False\n",
    "    \n",
    "    Replay = False\n",
    "    if(Replay == True):\n",
    "        options = parser.parse_args(args=['--rrf', 'feet02.rrf','--seconds', '25'])\n",
    "    else:\n",
    "        options = parser.parse_args(args=['--seconds', '30'])\n",
    "\n",
    "    opener = CameraOpener (options)\n",
    "    cam = opener.open_camera ()\n",
    "    \n",
    "    if(Replay == False):\n",
    "        cam.setUseCase('MODE_5_35FPS_600')#MODE_9_5FPS_2000 MODE_5_45FPS_500\n",
    "\n",
    "    #Print camera information\n",
    "    print_camera_info (cam)\n",
    "    print(\"isConnected\", cam.isConnected())\n",
    "    print(\"getFrameRate\", cam.getFrameRate())\n",
    "    print(\"UseCase\",cam.getCurrentUseCase())\n",
    "\n",
    "    # we will use this queue to synchronize the callback with the main\n",
    "    # thread, as drawing should happen in the main thread \n",
    "    x = queue.LifoQueue()\n",
    "    y = queue.LifoQueue()\n",
    "    z = queue.LifoQueue()\n",
    "    grayvalue = queue.LifoQueue()\n",
    "    l = MyListener(x,y,z,grayvalue)\n",
    "    cam.registerDataListener(l)\n",
    "    cam.startCapture()\n",
    "    \n",
    "    # create a loop that will run for a time (default 15 seconds)\n",
    "    process_event_queue (x, y, z, grayvalue, l, options.seconds, cam)\n",
    "    cam.stopCapture()\n",
    "    socket_sender.close_socket()\n",
    "    \n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "\n",
    "def process_event_queue (x,y,z,grayvalue, painter, seconds, cam):\n",
    "    show_3d_plane_img = False \n",
    "    SendData = True\n",
    "    \n",
    "    \n",
    "    # create a loop that will run for the given amount of time\n",
    "#     t_end = time.time() + seconds\n",
    "#     while time.time() < t_end:\n",
    "        \n",
    "#     key = ''\n",
    "    print(\"  Quit : Q\\n\")\n",
    "    while 1 :\n",
    "        try:\n",
    "            # try to retrieve an item from the queue.\n",
    "            # this will block until an item can be retrieved\n",
    "            # or the timeout of 1 second is hit\n",
    "            t_time = time.time()\n",
    "            \n",
    "            item_x = x.get(True, 0.5)\n",
    "            item_y = y.get(True, 0.5)\n",
    "            item_z = z.get(True, 0.5)\n",
    "            points3D = np.dstack((item_x,item_y,item_z))\n",
    "            item_grayvalue = grayvalue.get(True, 0.5)\n",
    "            #print('queue time:', (time.time()-t_time))\n",
    "        except queue.Empty:\n",
    "            # this will be thrown when the timeout is hit\n",
    "            break\n",
    "        else:\n",
    "            \n",
    "            t_time = time.time()\n",
    "            #if there have z value(z != 0) ==> True\n",
    "            Confidence_img = points3D[:,:,2] != 0 \n",
    "#             surface_plane, depthImg, plane_mask, best_sampts = RANSAM(points3D, ConfidenceIndex, ransac_iteration = 500, inliner_threshold = 0.003)\n",
    "            surface_plane, depthImg, plane_mask, best_sampts = RANSAM(points3D, Confidence_img, ransac_iteration = 50, inliner_threshold = 0.01)#1cm  0.003\n",
    "#             print('Ransam time:', (time.time()-t_time))\n",
    "            \n",
    "            #turn bool img to uint8\n",
    "            plane_img = plane_mask.astype(np.uint8)*255  \n",
    "            #turn item_grayvalue to uint8\n",
    "            grayvalue_img = cv2.convertScaleAbs(item_grayvalue)\n",
    "            \n",
    "            # y * -1 then compute the plane again ==> result : normal x * -1, z * -1            \n",
    "#             sampts = best_sampts.copy()\n",
    "#             sampts[:,1] = sampts[:,1] * -1\n",
    "#             print(best_sampts,sampts)\n",
    "#             print(surface_plane)\n",
    "#             print(get_Plane(sampts))\n",
    "            \n",
    "\n",
    "            #暫時不用，未來可能需要\n",
    "            #find large 四邊形 on the mask of plane, and find the center of it\n",
    "            quad_success, find_quad_img, approx, cx, cy = find_quadrilateral(plane_img)\n",
    "            \n",
    "#             find large 四邊形 successful ==> update cx, cy \n",
    "            if quad_success:\n",
    "                #check if the center and plane points are on the plane(for get the reasonable vale of 3d_point)\n",
    "                cx, cy, points_z, new_approx, find_quad_img = find_reasonable_value_of_center_vertices(cx, cy, plane_mask, approx, points3D, find_quad_img, kernel_size = 7)\n",
    "\n",
    "                #get mask of quadrilateral ==> no need to find new_approx (reasonable_value of edge points)??\n",
    "#                 mask_successful, quad_mask = find_quad_mask(new_approx, plane_img.shape)\n",
    "                mask_successful, quad_mask = find_quad_mask(approx, plane_img.shape)\n",
    "\n",
    "                #find circle\n",
    "                ret, px, py, circles_image = find_target_ellipse(grayvalue_img, quad_mask)\n",
    "                if ret:\n",
    "                    targetpos = (px, py)\n",
    "                    if(plane_mask[py,px] == False):\n",
    "                        px, py = find_points_on_plane(py, px, plane_mask, kernel_size = 7)\n",
    "#                     print(points3D[py, px])\n",
    "                    if(SendData):\n",
    "                        send_targetpos(px, py, points3D)\n",
    "            \n",
    "            \n",
    "#             #feet_detection\n",
    "#             feet_img, ellipse_list = feet_detection2(depthImg, mask_successful, quad_mask, height = 0.02, feet_height = 0.1)\n",
    "                \n",
    "            #show image\n",
    "            painter.paint (item_z, 'Depth')\n",
    "            painter.paint (circles_image, 'circles_image')\n",
    "#             painter.paint (plane_img, 'plane')\n",
    "#             painter.paint (find_quad_img, 'find_quad_img')\n",
    "#             painter.paint (quad_mask.astype(np.uint8)*255, 'quad_mask_img')\n",
    "#             painter.paint (feet_img, 'feet_img')\n",
    "#             painter.paint (Confidence_img.astype(np.uint8)*255, 'Confidence_img')\n",
    "            if(show_3d_plane_img):\n",
    "                show_plane(surface_plane)\n",
    "#             if len(new_approx) > 4:\n",
    "#                 plt.imshow(find_quad_img),plt.axis('off')\n",
    "#                 plt.show()\n",
    "            \n",
    "            #Send surface_plane and best_sampts\n",
    "            #receive data from unity\n",
    "            if(SendData):\n",
    "#                 socket_sender.create_socket()\n",
    "                send_plane_eq(surface_plane)\n",
    "#                 send_sample_points(best_sampts)\n",
    "                send_plane_points(points_z)\n",
    "#                 send_plane_center(cx, cy, points3D)\n",
    "                receive_data(cam)\n",
    "            \n",
    "#             print('time:', (time.time()-t_time))\n",
    "        \n",
    "        \n",
    "                \n",
    "        if(cv2.waitKey(10) & 0xFF == 113):\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of cameras connected:  1\n",
      "====================================\n",
      "        Camera information\n",
      "====================================\n",
      "Type:            PICOFLEXX\n",
      "Width:           224\n",
      "Height:          171\n",
      "Operation modes: 10\n",
      "    MODE_9_5FPS_2000\n",
      "    MODE_9_10FPS_1000\n",
      "    MODE_9_15FPS_700\n",
      "    MODE_9_25FPS_450\n",
      "    MODE_5_35FPS_600\n",
      "    MODE_5_45FPS_500\n",
      "    MODE_MIXED_30_5\n",
      "        this operation mode has 2 streams\n",
      "    MODE_MIXED_50_5\n",
      "        this operation mode has 2 streams\n",
      "    Low_Noise_Extended\n",
      "    Fast_Acquisition\n",
      "Lens parameters: 9\n",
      "    ('cx', 118.28559112548828)\n",
      "    ('cy', 87.74105072021484)\n",
      "    ('fx', 213.8031768798828)\n",
      "    ('fy', 213.8031768798828)\n",
      "    ('k1', 0.4155448377132416)\n",
      "    ('k2', -4.7316107749938965)\n",
      "    ('k3', 8.45906925201416)\n",
      "    ('p1', 7.605663946304829e-16)\n",
      "    ('p2', 4.939198934392371e-16)\n",
      "CameraInfo items: 8\n",
      "    ('BRIDGE_TYPE', 'Enclustra')\n",
      "    ('MODULE_IDENTIFIER', '00000000')\n",
      "    ('MODULE_IDENTIFIER_HASH', '558161692')\n",
      "    ('MODULE_SERIAL', '0')\n",
      "    ('MODULE_SUFFIX', '')\n",
      "    ('IMAGER', 'M2450_A12_AIO')\n",
      "    ('PROCESSING_NAME', 'Spectre')\n",
      "    ('PROCESSING_VERSION', '4.2.0.897')\n",
      "isConnected True\n",
      "getFrameRate 35\n",
      "UseCase MODE_5_35FPS_600\n",
      "  Quit : Q\n",
      "\n",
      "create socket successful\n",
      "close the socket successful\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "close the socket successful\n"
     ]
    }
   ],
   "source": [
    "socket_sender.close_socket()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  !jupyter nbconvert --to script HMD_Light_main.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import socket_sender\n",
    "# socket_sender.send('0 hello world')\n",
    "# data = socket_sender.receive()\n",
    "# print(data)\n",
    "# socket_sender.close_socket()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUUAAAD8CAYAAADgxrZUAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAA3BJREFUeJzt2yFuAkEAhtFdsocgeDy32DM3vUQ9vuEUbEXNZ1BNmQ28Z8f86suMmHnbtgmAX4fRAwD2RBQBQhQBQhQBQhQBQhQBQhQBQhQBQhQBYhk9YJqm6X47+1YDPM3heJ0fne0iiuvpMnoC8EY+74/PPJ8BQhQBQhQBQhQBQhQBQhQBQhQBQhQBQhQBQhQBQhQBQhQBQhQBQhQBQhQBQhQBQhQBQhQBQhQBQhQBQhQBQhQBQhQBQhQBQhQBQhQBQhQBQhQBQhQBQhQBQhQBQhQBQhQBQhQBQhQBQhQBQhQBQhQBQhQBQhQBQhQBQhQBQhQBQhQBQhQBQhQBQhQBQhQBQhQBYhk94NV8fH+NngD/Yj1dRk94CjdFgBBFgBBFgBBFgBBFgBBFgBBFgBBFgBBFgBBFgBBFgBBFgBBFgBBFgBBFgBBFgBBFgBBFgBBFgBBFgBBFgBBFgBBFgBBFgBBFgBBFgBBFgBBFgBBFgBBFgBBFgBBFgBBFgBBFgBBFgBBFgBBFgBBFgBBFgBBFgBBFgBBFgBBFgBBFgBBFgBBFgBBFgBBFgBBFgBBFgBBFgBBFgBBFgBBFgBBFgBBFgBBFgBBFgBBFgBBFgBBFgBBFgBBFgBBFgBBFgBBFgBBFgBBFgBBFgBBFgBBFgBBFgBBFgBBFgBBFgBBFgBBFgBBFgBBFgBBFgBBFgBBFgBBFgBBFgBBFgBBFgBBFgBBFgBBFgBBFgBBFgBBFgBBFgBBFgBBFgBBFgBBFgBBFgBBFgBBFgBBFgBBFgBBFgBBFgBBFgBBFgBBFgBBFgBBFgBBFgBBFgBBFgBBFgBBFgBBFgFhGD3g16+kyegLwB26KACGKACGKACGKACGKACGKACGKACGKACGKACGKACGKACGKACGKACGKACGKACGKACGKACGKACGKACGKACGKACGKACGKACGKACGKACGKACGKACGKACGKACGKACGKACGKACGKACGKACGKACGKACGKACGKACGKACGKACGKACGKACGKACGKACGKACGKACGKACGKACGKADFv2zZ6w3S/ncePAN7G4XidH53tIooAe+H5DBCiCBCiCBCiCBCiCBCiCBCiCBCiCBCiCBCiCBCiCBCiCBCiCBCiCBCiCBCiCBCiCBCiCBCiCBCiCBCiCBCiCBCiCBA/kAwY0HCs4OAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#show plane edge\n",
    "test = np.zeros((171,224), np.uint8)\n",
    "l = 40\n",
    "test[l:171-l,l:224-l] = 255\n",
    "test[test.shape[0]-1,:] = 255\n",
    "test[0,:] = 255\n",
    "plt.imshow(test),plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 40  40]]\n",
      "\n",
      " [[ 40 130]]\n",
      "\n",
      " [[183 130]]\n",
      "\n",
      " [[183  40]]]\n",
      "//\n",
      "[[[ 40  40]]\n",
      "\n",
      " [[ 40 130]]\n",
      "\n",
      " [[183 130]]\n",
      "\n",
      " [[183  40]]]\n",
      "________\n",
      "[[[  0 170]]\n",
      "\n",
      " [[223 170]]]\n",
      "//\n",
      "[[[  0 170]]\n",
      "\n",
      " [[223 170]]]\n",
      "________\n",
      "[[[  0   0]]\n",
      "\n",
      " [[223   0]]]\n",
      "//\n",
      "[[[  0   0]]\n",
      "\n",
      " [[223   0]]]\n",
      "________\n"
     ]
    }
   ],
   "source": [
    "(_, cnts, _) = cv2.findContours(test, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)\n",
    "cnts=sorted(cnts, key = cv2.contourArea, reverse = True)[:5]\n",
    "for c in cnts:\n",
    "    peri = cv2.arcLength(c, True)\n",
    "    approx = cv2.approxPolyDP(c, 0.08 * peri, True)\n",
    "    print(c)\n",
    "    print(\"//\")\n",
    "    print(approx)\n",
    "    print(\"________\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pylab as plt\n",
    "import numpy as np\n",
    "from matplotlib.path import Path\n",
    "\n",
    "width, height=224, 171\n",
    "\n",
    "polygon=[(129, 215), (140, 19), (11, 2), (1, 207)]\n",
    "poly_path=Path(polygon)\n",
    "\n",
    "x, y = np.mgrid[:height, :width]\n",
    "coors=np.hstack((x.reshape(-1, 1), y.reshape(-1,1))) # coors.shape is (4000000,2)\n",
    "\n",
    "mask = poly_path.contains_points(coors)\n",
    "mask= mask.reshape(height, width)\n",
    "plt.imshow(mask.astype(np.uint8)*255)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
