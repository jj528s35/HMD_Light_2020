{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import roypy\n",
    "import time\n",
    "import queue\n",
    "from sample_camera_info import print_camera_info\n",
    "from roypy_sample_utils import CameraOpener, add_camera_opener_options\n",
    "#from roypy_platform_utils import PlatformHelper\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import random\n",
    "import math\n",
    "from matplotlib.path import Path\n",
    "\n",
    "import socket_sender\n",
    "import _RANSAC\n",
    "import _Find_quad\n",
    "import _HMD_Light_function\n",
    "import _Tranform_Data\n",
    "\n",
    "\n",
    "try:\n",
    "    import roypycy\n",
    "except ImportError:\n",
    "    print(\"Pico Flexx backend requirements (roypycy) not installed properly\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def depth_range_mask(depthImg, low, height):\n",
    "    highter_region = depthImg > low\n",
    "    lower_region = depthImg < height\n",
    "    depth_mask = np.logical_and(highter_region, lower_region)\n",
    "    \n",
    "    depth_mask_ = depth_mask.astype(np.uint8)*255\n",
    "    \n",
    "    kernel_size = 5 #7\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT,(kernel_size, kernel_size))\n",
    "    #膨胀之后再腐蚀，在用来关闭前景对象里的小洞或小黑点\n",
    "    #开运算用于移除由图像噪音形成的斑点\n",
    "    opened = cv2.morphologyEx(depth_mask_, cv2.MORPH_OPEN, kernel)\n",
    "    depth_mask_ = cv2.morphologyEx(opened,cv2.MORPH_CLOSE,kernel)\n",
    "    \n",
    "     #find Contours with largest area \n",
    "    (_, cnts, _) = cv2.findContours(depth_mask_, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    if len(cnts) > 0:\n",
    "        cnt_ = sorted(cnts, key = cv2.contourArea, reverse = True)[0]\n",
    "        \n",
    "        peri = cv2.arcLength(cnt_, True)\n",
    "        approx = cv2.approxPolyDP(cnt_, 0.03* peri, True)\n",
    "        hull = cv2.convexHull(approx)\n",
    "        \n",
    "        #mask of max contour area\n",
    "        max_area_mask = np.zeros(depthImg.shape, dtype='uint8')  #依Contours圖形建立mask\n",
    "        cv2.drawContours(max_area_mask, [hull], -1, 255, -1) #255        →白色, -1→塗滿\n",
    "        \n",
    "        #mask the depth mask with max_area_mask\n",
    "        mask = cv2.add(depth_mask_, np.zeros(np.shape(depthImg), dtype='uint8'), mask=max_area_mask)\n",
    "        \n",
    "        depth_img_with_mask = cv2.add(depthImg, np.zeros(np.shape(depthImg), dtype=np.float32), mask=mask)\n",
    "    \n",
    "    else:\n",
    "        depth_img_with_mask = cv2.add(depthImg, np.zeros(np.shape(depthImg), dtype=np.float32), mask=depth_mask_)\n",
    "        mask = depth_mask_\n",
    "    \n",
    "    \n",
    "    \n",
    "    return mask, depth_img_with_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_edge_map(grayImage,depthImage):\n",
    "#     \"\"\"\n",
    "#     Canny Edge map\n",
    "#     turn grayImg from int32 to int8\n",
    "#     blur the grayImg then do Canny Edge\n",
    "#     \"\"\"\n",
    "#     low_threshold = 2\n",
    "#     high_threshold = 10\n",
    "    \n",
    "#     kernel_size = 3\n",
    "#     blur_gray = cv2.GaussianBlur(grayImage,(kernel_size, kernel_size), 0)\n",
    "#     Cannyedges = cv2.Canny(grayImage, low_threshold, high_threshold)#blur_gray\n",
    "    \n",
    "    \"\"\"\n",
    "    Threshold based Edge map\n",
    "    if depth between the pixel and its nearby pixels > near_depth_threshold, then labeled it\n",
    "    \"\"\"\n",
    "    s_time = time.time()\n",
    "    near_depth_threshold = 0.1 #10cm\n",
    "#     print(np.max(depthImage))\n",
    "    Threshold_based_edge = np.zeros((depthImage.shape[0],depthImage.shape[1]))\n",
    "    \n",
    "    h = depthImage.shape[0]\n",
    "    w = depthImage.shape[1]\n",
    "    depth_img_transform = np.zeros((h+1,w+1))\n",
    "    depth_img_transform[:h,:w] = depthImage\n",
    "    #check left up depth threshold\n",
    "    depth_img_transform[1:h+1,1:w+1] = depthImage\n",
    "    check_depth_threshold = abs(depthImage - depth_img_transform[:h,:w]) > near_depth_threshold\n",
    "    Threshold_based_edge = np.logical_or(Threshold_based_edge, check_depth_threshold)\n",
    "    #check up depth threshold\n",
    "    depth_img_transform[:h,:w] = depthImage\n",
    "    depth_img_transform[1:h+1,:w] = depthImage\n",
    "    check_depth_threshold = abs(depthImage - depth_img_transform[:depthImage.shape[0],:depthImage.shape[1]]) > near_depth_threshold\n",
    "    Threshold_based_edge = np.logical_or(Threshold_based_edge, check_depth_threshold)\n",
    "    #check Right up depth threshold\n",
    "    depth_img_transform[:h,:w] = depthImage\n",
    "    depth_img_transform[1:h+1,:w-1] = depthImage[:,1:w]\n",
    "    check_depth_threshold = abs(depthImage - depth_img_transform[:h,:w]) > near_depth_threshold\n",
    "    Threshold_based_edge = np.logical_or(Threshold_based_edge, check_depth_threshold)\n",
    "    #check Left depth threshold\n",
    "    depth_img_transform[:h,:w] = depthImage\n",
    "    depth_img_transform[:h,1:w+1] = depthImage\n",
    "    check_depth_threshold = abs(depthImage - depth_img_transform[:h,:w]) > near_depth_threshold\n",
    "    Threshold_based_edge = np.logical_or(Threshold_based_edge, check_depth_threshold)\n",
    "    #check Right depth threshold\n",
    "    depth_img_transform[:h,:w] = depthImage\n",
    "    depth_img_transform[:h,:w-1] = depthImage[:,1:w]\n",
    "    check_depth_threshold = abs(depthImage - depth_img_transform[:h,:w]) > near_depth_threshold\n",
    "    Threshold_based_edge = np.logical_or(Threshold_based_edge, check_depth_threshold)\n",
    "    #check Left down depth threshold\n",
    "    depth_img_transform[:h,:w] = depthImage\n",
    "    depth_img_transform[:h-1,1:w+1] = depthImage[1:h,:]\n",
    "    check_depth_threshold = abs(depthImage - depth_img_transform[:h,:w]) > near_depth_threshold\n",
    "    Threshold_based_edge = np.logical_or(Threshold_based_edge, check_depth_threshold)\n",
    "    #check down depth threshold\n",
    "    depth_img_transform[:h,:w] = depthImage\n",
    "    depth_img_transform[:h-1,:w] = depthImage[1:h,:]\n",
    "    check_depth_threshold = abs(depthImage - depth_img_transform[:h,:w]) > near_depth_threshold\n",
    "    Threshold_based_edge = np.logical_or(Threshold_based_edge, check_depth_threshold)\n",
    "    #check Right down depth threshold\n",
    "    depth_img_transform[:h,:w] = depthImage\n",
    "    depth_img_transform[:h-1,:w-1] = depthImage[1:h,1:w]\n",
    "    check_depth_threshold = abs(depthImage - depth_img_transform[:h,:w]) > near_depth_threshold\n",
    "    Threshold_based_edge = np.logical_or(Threshold_based_edge, check_depth_threshold)\n",
    "    \n",
    "    \n",
    "#     print('*get threshold edge: %.4f s'%(time.time()-s_time))\n",
    "    \"\"\"\n",
    "    Merge Canny Edge map and Threshold based Edge map\n",
    "    \"\"\"\n",
    "#     Edge_map = np.logical_or(Cannyedges,Threshold_based_edge)\n",
    "    \n",
    "    return Threshold_based_edge\n",
    "#     return Cannyedges,Threshold_based_edge, Edge_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyListener(roypy.IDepthDataListener):\n",
    "    def __init__(self, xqueue, yqueue, zqueue, grayValuequeue):\n",
    "        super(MyListener, self).__init__()\n",
    "        self.xqueue = xqueue\n",
    "        self.yqueue = yqueue\n",
    "        self.zqueue = zqueue\n",
    "        self.grayValuequeue = grayValuequeue\n",
    "        self.Listening = True\n",
    "\n",
    "    def onNewData(self, data):   \n",
    "        if(self.Listening):\n",
    "            t_time = time.time()\n",
    "            \n",
    "            xvalues = []\n",
    "            yvalues = []\n",
    "            zvalues = []\n",
    "            grayvalues = []\n",
    "            \n",
    "            values = roypycy.get_backend_data(data)\n",
    "\n",
    "            xvalues = values.x\n",
    "            yvalues = values.y\n",
    "            zvalues = values.z\n",
    "            grayvalues = values.grayValue\n",
    "\n",
    "            xarray = np.asarray(xvalues)\n",
    "            yarray = np.asarray(yvalues)\n",
    "            zarray = np.asarray(zvalues)\n",
    "            \n",
    "            \n",
    "            q_x = xarray.reshape (-1, data.width)        \n",
    "            self.xqueue.put(q_x)\n",
    "            q_y = yarray.reshape (-1, data.width)        \n",
    "            self.yqueue.put(q_y)\n",
    "            q_z = zarray.reshape (-1, data.width)        \n",
    "            self.zqueue.put(q_z)\n",
    "            \n",
    "            q_grayvalues = grayvalues.reshape (-1, data.width)        \n",
    "            self.grayValuequeue.put(q_grayvalues)\n",
    "            \n",
    "            #print('store time:', (time.time()-t_time))\n",
    "\n",
    "    def paint (self, data, name):\n",
    "        \"\"\"Called in the main thread, with data containing one of the items that was added to the\n",
    "        queue in onNewData.\n",
    "        \"\"\"\n",
    "        cv2.namedWindow(name, cv2.WINDOW_NORMAL)\n",
    "        cv2.imshow(name, data)\n",
    "        cv2.waitKey(1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def main ():\n",
    "    parser = argparse.ArgumentParser (usage = __doc__)\n",
    "    add_camera_opener_options (parser)\n",
    "    parser.add_argument (\"--seconds\", type=int, default=15, help=\"duration to capture data\")\n",
    "#     parser.add_argument (\"--SendData\", type=bool, default=False, help=\"SendData\")\n",
    "#     parser.add_argument (\"--Project_on_body\", type=bool, default=False, help=\"Project_on_body\")\n",
    "#     parser.add_argument (\"--Replay\", type=bool, default=False, help=\"Replay\")\n",
    "    \n",
    "    timer_show = False\n",
    "    \n",
    "    # 測試用 setting\n",
    "    _Replay = True\n",
    "    if(_Replay == True):\n",
    "        options = parser.parse_args(args=['--rrf', 'upper_line_body.rrf','--seconds', '25'])#0211_forward\n",
    "    else:\n",
    "        options = parser.parse_args(args=['--seconds', '30'])\n",
    "        \n",
    "#     _SendData = False\n",
    "#     if(_SendData == True):\n",
    "#         options = parser.parse_args(args=['--SendData', 'False'])\n",
    "#     else:\n",
    "#         options = parser.parse_args(args=['--SendData', 'True'])\n",
    "        \n",
    "#     _Project_on_body = False\n",
    "#     if(_Project_on_body == True):\n",
    "#         options = parser.parse_args(args=['--Project_on_body', 'False'])\n",
    "#     else:\n",
    "#         options = parser.parse_args(args=['--Project_on_body', 'True'])\n",
    "        \n",
    "\n",
    "    opener = CameraOpener (options)\n",
    "    cam = opener.open_camera ()\n",
    "    \n",
    "    if(_Replay == False):\n",
    "        cam.setUseCase('MODE_5_45FPS_500')#MODE_9_5FPS_2000 MODE_5_45FPS_500 MODE_5_35FPS_600\n",
    "\n",
    "    #Print camera information\n",
    "    print_camera_info (cam)\n",
    "    print(\"isConnected\", cam.isConnected())\n",
    "    print(\"getFrameRate\", cam.getFrameRate())\n",
    "    print(\"UseCase\",cam.getCurrentUseCase())\n",
    "\n",
    "    # we will use this queue to synchronize the callback with the main\n",
    "    # thread, as drawing should happen in the main thread \n",
    "    x = queue.LifoQueue()\n",
    "    y = queue.LifoQueue()\n",
    "    z = queue.LifoQueue()\n",
    "    grayvalue = queue.LifoQueue()\n",
    "    l = MyListener(x,y,z,grayvalue)\n",
    "    cam.registerDataListener(l)\n",
    "    cam.startCapture()\n",
    "    \n",
    "    # create a loop that will run for a time (default 15 seconds)\n",
    "    process_event_queue (x, y, z, grayvalue, l, options.seconds, cam)\n",
    "    cam.stopCapture()\n",
    "    socket_sender.close_socket()\n",
    "    \n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_event_queue (x,y,z,grayvalue, painter, seconds, cam):\n",
    "    SendData = True\n",
    "    Project_Type = 2  # 0: project on body, 1: project on floor, 2: calibration shift\n",
    "    \n",
    "    #initial\n",
    "    last_inliner_num = 20000\n",
    "    quad_mask = np.zeros((171,224))\n",
    "    circles_image = np.zeros((171,224,3))\n",
    "    \n",
    "    # create a loop that will run for the given amount of time\n",
    "    print(\"  Quit : Q\\n\")\n",
    "    while 1 :\n",
    "        t_time = time.time()\n",
    "        try:\n",
    "            # try to retrieve an item from the queue.\n",
    "            # this will block until an item can be retrieved\n",
    "            # or the timeout of 1 second is hit\n",
    "            t_time = time.time()\n",
    "            \n",
    "            item_x = x.get(True, 0.5)\n",
    "            item_y = y.get(True, 0.5)\n",
    "            item_z = z.get(True, 0.5)\n",
    "            points3D = np.dstack((item_x,item_y,item_z))\n",
    "            item_grayvalue = grayvalue.get(True, 0.5)\n",
    "            #print('queue time:', (time.time()-t_time))\n",
    "        except queue.Empty:\n",
    "            # this will be thrown when the timeout is hit\n",
    "            print(\"Empty\")\n",
    "#             break\n",
    "            continue\n",
    "        else:\n",
    "            #turn item_grayvalue to uint8\n",
    "            grayvalue_img = cv2.convertScaleAbs(item_grayvalue)\n",
    "            \n",
    "            #if there have z value(z != 0) ==> True\n",
    "            Confidence_img = points3D[:,:,2] != 0 \n",
    "            \n",
    "#             project on body\n",
    "            if Project_Type == 0: # project on body\n",
    "                # mask the depth image with depth range\n",
    "                depth_mask, depth_img_with_mask = depth_range_mask(item_z, 0.25, 0.6)#0.3m(30cm) 0.5m(50cm)\n",
    "\n",
    "                #turn bool img to uint8\n",
    "                depth_mask = depth_mask.astype(np.uint8)*255  \n",
    "\n",
    "                #find target plane\n",
    "                circles_image, plane_x, plane_y, plane_points = _HMD_Light_function.find_target_plane(grayvalue_img, depth_mask, Confidence_img, points3D)\n",
    "\n",
    "            \n",
    "                if(SendData ):#and find_target_success\n",
    "                    _Tranform_Data.send_target_plane(plane_points)\n",
    "\n",
    "                #show image\n",
    "                painter.paint (circles_image, 'circles_image')\n",
    "                \n",
    "#             Project_on_Floor\n",
    "            elif Project_Type == 1: #Project_on_Floor\n",
    "                #find plane by RANSAC\n",
    "                surface_plane, depthImg, plane_mask, best_sampts, best_inlinernum = \\\n",
    "                _RANSAC.RANSAM(points3D, Confidence_img, ransac_iteration = 50, inliner_threshold = 0.01, last_inliner_num = last_inliner_num)#1cm  0.003\n",
    "                last_inliner_num = best_inlinernum\n",
    "                \n",
    "                #turn bool img to uint8\n",
    "                plane_img = plane_mask.astype(np.uint8)*255 \n",
    "                \n",
    "                #find large 四邊形 on the mask of plane, and find the center of it\n",
    "                find_quad_success, find_quad_img, approx, cx, cy = _Find_quad.find_quadrilateral(plane_img)\n",
    "                \n",
    "                if find_quad_success:\n",
    "                    # Get the quad_mask\n",
    "                    mask_success, quad_mask = _Find_quad.find_quad_mask(approx, plane_img.shape)\n",
    "                    if mask_success:\n",
    "                        #find target circle\n",
    "                        find_target_success, px, py, circles_image = _HMD_Light_function.find_target_circle(grayvalue_img, quad_mask, plane_mask)\n",
    "                        \n",
    "                        #find single targetline\n",
    "#                         find_target_success, circles_image, px, py, minX, minY, maxX, maxY = \\\n",
    "#                                 _HMD_Light_function.find_targetLine_pos(grayvalue_img, quad_mask, plane_mask)\n",
    "                        \n",
    "                        #find line => not good result\n",
    "#                         line_image = _HMD_Light_function.find_line(grayvalue_img, quad_mask)\n",
    "            \n",
    "                        if(SendData and find_target_success):\n",
    "                            _Tranform_Data.send_targetpos(px, py, points3D)\n",
    "                            \n",
    "                            vx, vy = _HMD_Light_function.find_plane_forward_vector(px, approx, plane_mask, 30)\n",
    "                            _Tranform_Data.send_forward_vector(px, py, vx, vy, points3D)\n",
    "\n",
    "#                             _Tranform_Data.send_forward_vector(minX, minY, maxX, maxY, points3D)\n",
    "                            \n",
    "                            # 2個send中要有延遲(show image 或 print)才不會卡\n",
    "#                             print(\"1\") \n",
    "                            \n",
    "        \n",
    "                #show image\n",
    "                painter.paint (item_z, 'Depth')\n",
    "                painter.paint (grayvalue_img, 'grayvalue_img')\n",
    "#                 painter.paint (plane_img, 'plane_mask')\n",
    "                painter.paint (circles_image, 'circles_image')\n",
    "                \n",
    "                \n",
    "                if(SendData):\n",
    "                    _Tranform_Data.send_plane_eq(surface_plane)\n",
    "                        \n",
    "            elif Project_Type == 2: #Calibration => 調整 lenshift\n",
    "                #find plane by RANSAC\n",
    "                surface_plane, depthImg, plane_mask, best_sampts, best_inlinernum = \\\n",
    "                _RANSAC.RANSAM(points3D, Confidence_img, ransac_iteration = 50, inliner_threshold = 0.01, last_inliner_num = last_inliner_num)#1cm  0.003\n",
    "                last_inliner_num = best_inlinernum\n",
    "                \n",
    "                #turn bool img to uint8\n",
    "                plane_img = plane_mask.astype(np.uint8)*255 \n",
    "                \n",
    "                #find large 四邊形 on the mask of plane, and find the center of it\n",
    "                find_quad_success, find_quad_img, approx, cx, cy = _Find_quad.find_quadrilateral(plane_img)\n",
    "                \n",
    "                if find_quad_success:\n",
    "                    # Get the quad_mask\n",
    "                    mask_success, quad_mask = _Find_quad.find_quad_mask(approx, plane_img.shape)\n",
    "                    if mask_success:\n",
    "                        #find target circle\n",
    "                        find_target_success, px, py, circles_image = _HMD_Light_function.find_target_circle(grayvalue_img, quad_mask, plane_mask)\n",
    "            \n",
    "                        if(SendData and find_target_success):\n",
    "                            _Tranform_Data.send_targetpos(px, py, points3D)\n",
    "                            \n",
    "                            vx, vy = _HMD_Light_function.find_plane_forward_vector(px, approx, plane_mask, 30)\n",
    "                            _Tranform_Data.send_forward_vector(px, py, vx, vy, points3D)\n",
    "                            \n",
    "        \n",
    "                #show image\n",
    "                painter.paint (circles_image, 'circles_image')\n",
    "                \n",
    "                \n",
    "                if(SendData):\n",
    "                    _Tranform_Data.send_plane_eq(surface_plane)\n",
    "                        \n",
    "        \n",
    "#             print('time:', (time.time()-t_time))\n",
    "        \n",
    "        \n",
    "                \n",
    "        if(cv2.waitKey(10) & 0xFF == 113):#耗時0.01s\n",
    "            break\n",
    "            \n",
    "        if(SendData):\n",
    "            stop = _Tranform_Data.receive_data(cam)\n",
    "            if stop:\n",
    "                break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of cameras connected:  1\n",
      "====================================\n",
      "        Camera information\n",
      "====================================\n",
      "Type:            PICOFLEXX\n",
      "Width:           224\n",
      "Height:          171\n",
      "Operation modes: 10\n",
      "    MODE_9_5FPS_2000\n",
      "    MODE_9_10FPS_1000\n",
      "    MODE_9_15FPS_700\n",
      "    MODE_9_25FPS_450\n",
      "    MODE_5_35FPS_600\n",
      "    MODE_5_45FPS_500\n",
      "    MODE_MIXED_30_5\n",
      "        this operation mode has 2 streams\n",
      "    MODE_MIXED_50_5\n",
      "        this operation mode has 2 streams\n",
      "    Low_Noise_Extended\n",
      "    Fast_Acquisition\n",
      "Lens parameters: 9\n",
      "    ('cx', 118.28559112548828)\n",
      "    ('cy', 87.74105072021484)\n",
      "    ('fx', 213.8031768798828)\n",
      "    ('fy', 213.8031768798828)\n",
      "    ('k1', 0.4155448377132416)\n",
      "    ('k2', -4.7316107749938965)\n",
      "    ('k3', 8.45906925201416)\n",
      "    ('p1', 7.605663946304829e-16)\n",
      "    ('p2', 4.939198934392371e-16)\n",
      "CameraInfo items: 8\n",
      "    ('BRIDGE_TYPE', 'Enclustra')\n",
      "    ('MODULE_IDENTIFIER', '00000000')\n",
      "    ('MODULE_IDENTIFIER_HASH', '558161692')\n",
      "    ('MODULE_SERIAL', '0')\n",
      "    ('MODULE_SUFFIX', '')\n",
      "    ('IMAGER', 'M2450_A12_AIO')\n",
      "    ('PROCESSING_NAME', 'Spectre')\n",
      "    ('PROCESSING_VERSION', '4.2.0.897')\n",
      "isConnected True\n",
      "getFrameRate 45\n",
      "UseCase MODE_5_45FPS_500\n",
      "  Quit : Q\n",
      "\n",
      "create socket successful\n",
      "receive 2 stop!\n",
      "close the socket successful\n",
      "close the socket successful\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "close the socket successful\n"
     ]
    }
   ],
   "source": [
    "socket_sender.close_socket()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !jupyter nbconvert --to script _HMD_Light_main.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#project on body\n",
    "\n",
    "#                 #find single targetline\n",
    "#                 find_target_success, circles_image, px, py, minX, minY, maxX, maxY = \\\n",
    "#                                 _HMD_Light_function.find_targetLine_pos(grayvalue_img, depth_mask, Confidence_img)\n",
    "                \n",
    "                    #show target points in 3d image        \n",
    "#                 _HMD_Light_function.show_plane(plane_x, plane_y, points3D)\n",
    "\n",
    "# send data\n",
    " # #                    find the 3d point for reprojected u v \n",
    "#                     _Tranform_Data.send_target_plane(plane_x, plane_y, points3D)               \n",
    "#                     for single targetline\n",
    "#                     _Tranform_Data.send_targetpos(px, py, points3D)\n",
    "#                     _Tranform_Data.send_forward_vector(minX, minY, maxX, maxY, points3D)\n",
    "\n",
    "# show image\n",
    "#                 painter.paint (item_z, 'Depth')\n",
    "#                 painter.paint (depth_img_with_mask, 'depth_img_with_mask')\n",
    "#                 painter.paint (grayvalue_img, 'grayvalue_img')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
