{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import roypy\n",
    "import time\n",
    "import queue\n",
    "from sample_camera_info import print_camera_info\n",
    "from roypy_sample_utils import CameraOpener, add_camera_opener_options\n",
    "#from roypy_platform_utils import PlatformHelper\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import random\n",
    "import math\n",
    "from matplotlib.path import Path\n",
    "\n",
    "import socket_sender\n",
    "import _RANSAC\n",
    "import _Find_quad\n",
    "import _HMD_Light_function\n",
    "import _Tranform_Data\n",
    "import _feet_detection\n",
    "import _Record_img\n",
    "import _Feet_detection_by_center\n",
    "\n",
    "\n",
    "try:\n",
    "    import roypycy\n",
    "except ImportError:\n",
    "    print(\"Pico Flexx backend requirements (roypycy) not installed properly\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def depth_range_mask(depthImg, low, height):\n",
    "    highter_region = depthImg > low\n",
    "    lower_region = depthImg < height\n",
    "    depth_mask = np.logical_and(highter_region, lower_region)\n",
    "    \n",
    "    depth_mask_ = depth_mask.astype(np.uint8)*255\n",
    "    \n",
    "    kernel_size = 5 #7\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT,(kernel_size, kernel_size))\n",
    "    #膨胀之后再腐蚀，在用来关闭前景对象里的小洞或小黑点\n",
    "    #开运算用于移除由图像噪音形成的斑点\n",
    "    opened = cv2.morphologyEx(depth_mask_, cv2.MORPH_OPEN, kernel)\n",
    "    depth_mask_ = cv2.morphologyEx(opened,cv2.MORPH_CLOSE,kernel)\n",
    "    \n",
    "     #find Contours with largest area \n",
    "    (_, cnts, _) = cv2.findContours(depth_mask_, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    if len(cnts) > 0:\n",
    "        cnt_ = sorted(cnts, key = cv2.contourArea, reverse = True)[0]\n",
    "        \n",
    "        peri = cv2.arcLength(cnt_, True)\n",
    "        approx = cv2.approxPolyDP(cnt_, 0.03* peri, True)\n",
    "        hull = cv2.convexHull(approx)\n",
    "        \n",
    "        #mask of max contour area\n",
    "        max_area_mask = np.zeros(depthImg.shape, dtype='uint8')  #依Contours圖形建立mask\n",
    "        cv2.drawContours(max_area_mask, [hull], -1, 255, -1) #255        →白色, -1→塗滿\n",
    "        \n",
    "        #mask the depth mask with max_area_mask\n",
    "        mask = cv2.add(depth_mask_, np.zeros(np.shape(depthImg), dtype='uint8'), mask=max_area_mask)\n",
    "        \n",
    "        depth_img_with_mask = cv2.add(depthImg, np.zeros(np.shape(depthImg), dtype=np.float32), mask=mask)\n",
    "    \n",
    "    else:\n",
    "        depth_img_with_mask = cv2.add(depthImg, np.zeros(np.shape(depthImg), dtype=np.float32), mask=depth_mask_)\n",
    "        mask = depth_mask_\n",
    "    \n",
    "    \n",
    "    \n",
    "    return mask, depth_img_with_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyListener(roypy.IDepthDataListener):\n",
    "    def __init__(self, xqueue, yqueue, zqueue, grayValuequeue):\n",
    "        super(MyListener, self).__init__()\n",
    "        self.xqueue = xqueue\n",
    "        self.yqueue = yqueue\n",
    "        self.zqueue = zqueue\n",
    "        self.grayValuequeue = grayValuequeue\n",
    "        self.Listening = True\n",
    "\n",
    "    def onNewData(self, data):   \n",
    "        if(self.Listening):\n",
    "            t_time = time.time()\n",
    "            \n",
    "            xvalues = []\n",
    "            yvalues = []\n",
    "            zvalues = []\n",
    "            grayvalues = []\n",
    "            \n",
    "            values = roypycy.get_backend_data(data)\n",
    "\n",
    "            xvalues = values.x\n",
    "            yvalues = values.y\n",
    "            zvalues = values.z\n",
    "            grayvalues = values.grayValue\n",
    "\n",
    "            xarray = np.asarray(xvalues)\n",
    "            yarray = np.asarray(yvalues)\n",
    "            zarray = np.asarray(zvalues)\n",
    "            \n",
    "            \n",
    "            q_x = xarray.reshape (-1, data.width)        \n",
    "            self.xqueue.put(q_x)\n",
    "            q_y = yarray.reshape (-1, data.width)        \n",
    "            self.yqueue.put(q_y)\n",
    "            q_z = zarray.reshape (-1, data.width)        \n",
    "            self.zqueue.put(q_z)\n",
    "            \n",
    "            q_grayvalues = grayvalues.reshape (-1, data.width)        \n",
    "            self.grayValuequeue.put(q_grayvalues)\n",
    "            \n",
    "            #print('store time:', (time.time()-t_time))\n",
    "\n",
    "    def paint (self, data, name):\n",
    "        \"\"\"Called in the main thread, with data containing one of the items that was added to the\n",
    "        queue in onNewData.\n",
    "        \"\"\"\n",
    "        cv2.namedWindow(name, cv2.WINDOW_NORMAL)\n",
    "        cv2.imshow(name, data)\n",
    "        cv2.waitKey(1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def main ():\n",
    "    parser = argparse.ArgumentParser (usage = __doc__)\n",
    "    add_camera_opener_options (parser)\n",
    "    parser.add_argument (\"--seconds\", type=int, default=15, help=\"duration to capture data\")\n",
    "    parser.add_argument (\"--SendData\", type=bool, default=False, help=\"SendData\")\n",
    "    parser.add_argument (\"--Project_Type\", type=int, default=0, help=\"0: Project_on_body, 1: Project_on_floor\")\n",
    "    \n",
    "    timer_show = False\n",
    "    \n",
    "    # 測試用 setting\n",
    "    _Replay = True\n",
    "    if(_Replay == True):\n",
    "#         options = parser.parse_args(args=['--rrf', 'upper_line_body.rrf','--seconds', '25', '--Project_Type', '0'])\n",
    "        # project on body: upper_line_body.rrf\n",
    "        \n",
    "        options = parser.parse_args(args=['--rrf', 'feet.rrf','--seconds', '25', '--Project_Type', '1'])\n",
    "#         options = parser.parse_args(args=['--rrf', 'feet_35fps_3.rrf','--seconds', '25', '--Project_Type', '2'])\n",
    "        # project on floor: feet_35fps.rrf  feet_35fps_2.rrf feet0221 feet\n",
    "    else:\n",
    "#         options = parser.parse_args(args=['--seconds', '30', '--Project_Type', '0'])\n",
    "        options = parser.parse_args(args=['--seconds', '30', '--Project_Type', '1'])\n",
    "#         options = parser.parse_args(args=['--seconds', '30', '--Project_Type', '2'])\n",
    "#         options = parser.parse_args(args=['--seconds', '30', '--Project_Type', '3'])\n",
    "        \n",
    "\n",
    "    opener = CameraOpener (options)\n",
    "    cam = opener.open_camera ()\n",
    "    \n",
    "    if(_Replay == False):\n",
    "        #MODE_9_5FPS_2000 MODE_5_45FPS_500 MODE_5_35FPS_600\n",
    "#         cam.setUseCase('MODE_5_45FPS_500') # body\n",
    "        cam.setUseCase('MODE_5_35FPS_600') #floor\n",
    "\n",
    "    #Print camera information\n",
    "    print_camera_info (cam)\n",
    "    print(\"isConnected\", cam.isConnected())\n",
    "    print(\"getFrameRate\", cam.getFrameRate())\n",
    "    print(\"UseCase\",cam.getCurrentUseCase())\n",
    "\n",
    "    # we will use this queue to synchronize the callback with the main\n",
    "    # thread, as drawing should happen in the main thread \n",
    "    x = queue.LifoQueue()\n",
    "    y = queue.LifoQueue()\n",
    "    z = queue.LifoQueue()\n",
    "    grayvalue = queue.LifoQueue()\n",
    "    l = MyListener(x,y,z,grayvalue)\n",
    "    cam.registerDataListener(l)\n",
    "    cam.startCapture()\n",
    "    \n",
    "    # create a loop that will run for a time (default 15 seconds)\n",
    "    process_event_queue (x, y, z, grayvalue, l, options.seconds, options.Project_Type, cam)\n",
    "    cam.stopCapture()\n",
    "    socket_sender.close_socket()\n",
    "    \n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_event_queue (x,y,z,grayvalue, painter, seconds, Project_Type, cam):\n",
    "    SendData = False\n",
    "    Record_img = False\n",
    "#     Project_Type = 0  # 0: project on body, 1: project on floor, 3: calibration shift\n",
    "\n",
    "    _Tranform_Data.send_project_type(Project_Type)\n",
    "    _Tranform_Data.send_project_type(Project_Type)\n",
    "    \n",
    "    #initial\n",
    "    last_inliner_num = 20000\n",
    "    quad_mask = np.zeros((171,224))\n",
    "    circles_image = np.zeros((171,224,3))\n",
    "    num_of_frame = 0\n",
    "    feet_mask = np.ones((171,224))\n",
    "    \n",
    "    # create a loop that will run for the given amount of time\n",
    "    print(\"  Quit : Q\\n\")\n",
    "    while 1 :\n",
    "        t_time = time.time()\n",
    "        try:\n",
    "            # try to retrieve an item from the queue.\n",
    "            # this will block until an item can be retrieved\n",
    "            # or the timeout of 1 second is hit\n",
    "            t_time = time.time()\n",
    "            \n",
    "            item_x = x.get(True, 0.5)\n",
    "            item_y = y.get(True, 0.5)\n",
    "            item_z = z.get(True, 0.5)\n",
    "            points3D = np.dstack((item_x,item_y,item_z))\n",
    "            item_grayvalue = grayvalue.get(True, 0.5)\n",
    "            #print('queue time:', (time.time()-t_time))\n",
    "        except queue.Empty:\n",
    "            # this will be thrown when the timeout is hit\n",
    "            print(\"Empty\")\n",
    "#             break\n",
    "            continue\n",
    "        else:\n",
    "            num_of_frame = num_of_frame + 1\n",
    "            \n",
    "            #turn item_grayvalue to uint8\n",
    "            grayvalue_img = cv2.convertScaleAbs(item_grayvalue)\n",
    "            \n",
    "            #if there have z value(z != 0) ==> True\n",
    "            Confidence_img = points3D[:,:,2] != 0 \n",
    "            \n",
    "            \"\"\"project on body -- 45fps\"\"\"\n",
    "            if Project_Type == 0: # project on body\n",
    "                # mask the depth image with depth range\n",
    "                depth_mask, depth_img_with_mask = depth_range_mask(item_z, 0.25, 0.6)#0.3m(30cm) 0.5m(50cm)\n",
    "\n",
    "                #turn bool img to uint8\n",
    "                depth_mask = depth_mask.astype(np.uint8)*255  \n",
    "\n",
    "                #find target plane\n",
    "                find_target_plane_success, circles_image, plane_x, plane_y, plane_points = \\\n",
    "                    _HMD_Light_function.find_target_plane(grayvalue_img, depth_mask, Confidence_img, points3D)\n",
    "\n",
    "            \n",
    "                if(SendData and find_target_plane_success):\n",
    "                    _Tranform_Data.send_target_plane(plane_points)\n",
    "                   \n",
    "\n",
    "                #show image\n",
    "                painter.paint (circles_image, 'circles_image')\n",
    "                painter.paint (Confidence_img.astype(np.uint8)*255 , 'Confidence_img')\n",
    "                \n",
    "                #Record\n",
    "                if Record_img and num_of_frame < 200:\n",
    "                    _Record_img.storeimg((grayvalue_img, circles_image), num_of_frame, 'project_on_body', string = 'body0_')\n",
    "                \n",
    "            \n",
    "            elif Project_Type == 1: #Project_on_Floor\n",
    "                \"\"\"project on Floor\"\"\"\n",
    "                #find plane by RANSAC\n",
    "                surface_plane, depthImg, plane_mask, best_sampts, best_inlinernum = \\\n",
    "                _RANSAC.RANSAM(points3D, Confidence_img, ransac_iteration = 50, inliner_threshold = 0.01, last_inliner_num = last_inliner_num)#1cm  0.003\n",
    "                last_inliner_num = best_inlinernum\n",
    "                \n",
    "                #turn bool img to uint8\n",
    "                plane_img = plane_mask.astype(np.uint8)*255 \n",
    "                \n",
    "                #find large 四邊形 on the mask of plane, and find the center of it\n",
    "                find_quad_success, find_quad_img, approx, cx, cy = _Find_quad.find_quadrilateral(plane_img)\n",
    "                \n",
    "                if find_quad_success:\n",
    "                    # Get the quad_mask\n",
    "                    mask_success, quad_mask = _Find_quad.find_quad_mask(approx, plane_img.shape)\n",
    "                    if mask_success:\n",
    "                        #Confi_mask : 去掉雜訊多的區域\n",
    "                        Confi_mask = np.zeros((171,224), np.uint8)\n",
    "                        cv2.circle(Confi_mask, (Confi_mask.shape[1]//2,Confi_mask.shape[0]//2), 110, 255 , -1)\n",
    "                        feet_img, height_mask_region, new_feet_mask, f_mask, feet_top, Non_VR_feet_top = \\\n",
    "                            _Feet_detection_by_center.feet_detection(depthImg, quad_mask, feet_mask, Confi_mask, height = 0.03, feet_height = 0.10)\n",
    "                        \n",
    "                        if new_feet_mask:\n",
    "                            feet_mask = f_mask\n",
    "                        \n",
    "#                         feet_img, height_mask_region, feet_top = \\\n",
    "#                             _Feet_detection_by_center.feet_center_detection(depthImg, quad_mask, Confi_mask, height = 0.03, feet_height = 0.10, VR_user = True)\n",
    "                        \n",
    "                        # fit ellipse\n",
    "#                         feet_img, height_mask_region, ellipse_list, feet_top = \\\n",
    "#                             _feet_detection.feet_top_detection(depthImg, quad_mask, height = 0.05, feet_height = 0.10, VR_user = True) #5-8cm \n",
    "            \n",
    "                        find_feet_top_success, centerX, centerY, minX, minY, maxX, maxY, feet_img = \\\n",
    "                            _Feet_detection_by_center.find_center_and_vector_by_top(feet_top, feet_img)\n",
    "                        \n",
    "                        if(find_feet_top_success):\n",
    "                            center_success, feet_img, px, py = _Feet_detection_by_center.find_plane_center\\\n",
    "                                                    (centerX, centerY, minX, minY, maxX, maxY, feet_img, points3D, plane_mask, plane_size = 0.4)\n",
    "            \n",
    "                        if(SendData and find_feet_top_success):\n",
    "                            _Tranform_Data.send_forward_vector(minX, minY, maxX, maxY, points3D)\n",
    "        \n",
    "                            if center_success:\n",
    "                                _Tranform_Data.send_targetpos(px, py, points3D)\n",
    "                            \n",
    "\n",
    "#                 print(num_of_frame, (minX - maxX), (minY - maxY))          \n",
    "                #show image\n",
    "#                 painter.paint (depthImg, 'Depth')\n",
    "                painter.paint (grayvalue_img, 'grayvalue_img')\n",
    "#                 painter.paint (feet_mask.astype(np.uint8)*255 , 'feet_mask')\n",
    "                painter.paint (feet_img, 'feet_img')\n",
    "#                 painter.paint (height_mask_region, 'height_mask_region')\n",
    "                \n",
    "#                 painter.paint (Confi_mask.astype(np.uint8), 'Confi_mask')\n",
    "#                 painter.paint (quad_mask.astype(np.uint8)*255, 'quad_mask')\n",
    "#                 painter.paint (np.logical_and(Confi_mask,quad_mask).astype(np.uint8)*255, 'mask')\n",
    "                \n",
    "                #Record\n",
    "                if Record_img and num_of_frame > 60 and num_of_frame < 360:\n",
    "                     _Record_img.storeimg((grayvalue_img,height_mask_region,feet_img), num_of_frame, 'project_on_floor',string = 'floor1_')\n",
    "                \n",
    "                if(SendData):\n",
    "                    _Tranform_Data.send_plane_eq(surface_plane)\n",
    "       \n",
    "            elif Project_Type == 3: #Calibration => 調整 lenshift\n",
    "                \"\"\"Calibration\"\"\" \n",
    "                #find plane by RANSAC\n",
    "                surface_plane, depthImg, plane_mask, best_sampts, best_inlinernum = \\\n",
    "                _RANSAC.RANSAM(points3D, Confidence_img, ransac_iteration = 50, inliner_threshold = 0.01, last_inliner_num = last_inliner_num)#1cm  0.003\n",
    "                last_inliner_num = best_inlinernum\n",
    "                \n",
    "                #turn bool img to uint8\n",
    "                plane_img = plane_mask.astype(np.uint8)*255 \n",
    "                \n",
    "                #find large 四邊形 on the mask of plane, and find the center of it\n",
    "                find_quad_success, find_quad_img, approx, cx, cy = _Find_quad.find_quadrilateral(plane_img)\n",
    "                \n",
    "                if find_quad_success:\n",
    "                    # Get the quad_mask\n",
    "                    mask_success, quad_mask = _Find_quad.find_quad_mask(approx, plane_img.shape)\n",
    "                    if mask_success:\n",
    "                        #find target circle\n",
    "                        find_target_success, px, py, circles_image = _HMD_Light_function.find_target_circle(grayvalue_img, quad_mask, plane_mask)\n",
    "            \n",
    "                        if(SendData and find_target_success):\n",
    "                            _Tranform_Data.send_targetpos(px, py, points3D)\n",
    "                            \n",
    "                            vx, vy = _HMD_Light_function.find_plane_forward_vector(px, approx, plane_mask, 30)\n",
    "                            _Tranform_Data.send_forward_vector(px, py, vx, vy, points3D)\n",
    "                            \n",
    "        \n",
    "                #show image\n",
    "                painter.paint (circles_image, 'circles_image')\n",
    "                \n",
    "                \n",
    "                if(SendData):\n",
    "                    _Tranform_Data.send_plane_eq(surface_plane)\n",
    "                        \n",
    "        \n",
    "                \n",
    "            else: \n",
    "                break\n",
    "        \n",
    "#         print('time:', (time.time()-t_time))\n",
    "        \n",
    "        if(cv2.waitKey(10) & 0xFF == 113):#耗時0.01s\n",
    "            break\n",
    "\n",
    "        if(SendData):\n",
    "            stop = _Tranform_Data.receive_data(cam)\n",
    "            if stop:\n",
    "                break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filename: feet.rrf\n",
      "====================================\n",
      "        Camera information\n",
      "====================================\n",
      "Type:            PICOFLEXX\n",
      "Width:           224\n",
      "Height:          171\n",
      "Operation modes: 1\n",
      "    MODE_PLAYBACK\n",
      "        this operation mode has 452981552 streams\n",
      "Lens parameters: 9\n",
      "    ('cx', 118.28559112548828)\n",
      "    ('cy', 87.74105072021484)\n",
      "    ('fx', 213.8031768798828)\n",
      "    ('fy', 213.8031768798828)\n",
      "    ('k1', 0.4155448377132416)\n",
      "    ('k2', -4.7316107749938965)\n",
      "    ('k3', 8.45906925201416)\n",
      "    ('p1', 7.605663946304829e-16)\n",
      "    ('p2', 4.939198934392371e-16)\n",
      "CameraInfo items: 0\n",
      "isConnected True\n",
      "getFrameRate 0\n",
      "UseCase MODE_PLAYBACK\n",
      "create socket successful\n",
      "  Quit : Q\n",
      "\n",
      "close the socket successful\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "close the socket successful\n"
     ]
    }
   ],
   "source": [
    "socket_sender.close_socket()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !jupyter nbconvert --to script _HMD_Light_main.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#project on body 20200218\n",
    "\n",
    "#                 #find single targetline\n",
    "#                 find_target_success, circles_image, px, py, minX, minY, maxX, maxY = \\\n",
    "#                                 _HMD_Light_function.find_targetLine_pos(grayvalue_img, depth_mask, Confidence_img)\n",
    "                \n",
    "                    #show target points in 3d image        \n",
    "#                 _HMD_Light_function.show_plqane(plane_x, plane_y, points3D)\n",
    "\n",
    "# send data\n",
    " # #                    find the 3d point for reprojected u v \n",
    "#                     _Tranform_Data.send_target_plane(plane_x, plane_y, points3D)               \n",
    "#                     for single targetline\n",
    "#                     _Tranform_Data.send_targetpos(px, py, points3D)\n",
    "#                     _Tranform_Data.send_forward_vector(minX, minY, maxX, maxY, points3D)\n",
    "\n",
    "# show image\n",
    "#                 painter.paint (item_z, 'Depth')\n",
    "#                 painter.paint (depth_img_with_mask, 'depth_img_with_mask')\n",
    "#                 painter.paint (grayvalue_img, 'grayvalue_img')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#project on floor 20200213\n",
    " #                find target circle\n",
    "#                         find_target_success, px, py, circles_image = _HMD_Light_function.find_target_circle(grayvalue_img, quad_mask, plane_mask)\n",
    "                        \n",
    "#                         #find single targetline\n",
    "# #                         find_target_success, circles_image, px, py, minX, minY, maxX, maxY = \\\n",
    "# #                                 _HMD_Light_function.find_targetLine_pos(grayvalue_img, quad_mask, plane_mask)\n",
    "                        \n",
    "#                         #find line => not good result\n",
    "# #                         line_image = _HMD_Light_function.find_line(grayvalue_img, quad_mask)\n",
    "\n",
    "\n",
    "\n",
    "#                         if(SendData and find_target_success):\n",
    "#                             _Tranform_Data.send_targetpos(px, py, points3D)\n",
    "                            \n",
    "#                             vx, vy = _HMD_Light_function.find_plane_forward_vector(px, approx, plane_mask, 30)\n",
    "#                             _Tranform_Data.send_forward_vector(px, py, vx, vy, points3D)\n",
    "\n",
    "# #                             _Tranform_Data.send_forward_vector(minX, minY, maxX, maxY, points3D)\n",
    "                            \n",
    "#                             # 2個send中要有延遲(show image 或 print)才不會卡\n",
    "# #                             print(\"1\") \n",
    "\n",
    "\n",
    "# if(SendData):\n",
    "#                     _Tranform_Data.send_plane_eq(surface_plane)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = np.zeros((5,4))\n",
    "# print(len(a.shape))\n",
    "# a1 = np.ones((5,4))\n",
    "# a2 = (a,a1)\n",
    "# _Record_img.storeimg(a2, 0, string = '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "mask = np.zeros((171,224), np.uint8)\n",
    "cv2.circle(mask, (mask.shape[1]//2,mask.shape[0]//2), 110, 255 , -1)\n",
    "plt.imshow(mask.astype(np.uint8)*255)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !jupyter nbconvert --to script _HMD_Light_main.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "                    \n",
    "#             elif Project_Type == 2: #Project_on_Floor go forward\n",
    "#                 \"\"\"project on Floor go forward\"\"\"\n",
    "#                 #find plane by RANSAC\n",
    "#                 surface_plane, depthImg, plane_mask, best_sampts, best_inlinernum = \\\n",
    "#                 _RANSAC.RANSAM(points3D, Confidence_img, ransac_iteration = 50, inliner_threshold = 0.02, last_inliner_num = last_inliner_num)#1cm  0.003\n",
    "#                 last_inliner_num = best_inlinernum\n",
    "                \n",
    "#                 #turn bool img to uint8\n",
    "#                 plane_img = plane_mask.astype(np.uint8)*255 \n",
    "                \n",
    "#                 #find large 四邊形 on the mask of plane, and find the center of it\n",
    "#                 find_quad_success, find_quad_img, approx, cx, cy = _Find_quad.find_quadrilateral(plane_img)\n",
    "                \n",
    "#                 if find_quad_success:\n",
    "#                     # Get the quad_mask\n",
    "#                     mask_success, quad_mask = _Find_quad.find_quad_mask(approx, plane_img.shape)\n",
    "#                     if mask_success:\n",
    "#                         feet_img, height_mask_region, ellipse_list, feet_list = \\\n",
    "#                             _feet_detection.feet_list_detection(depthImg, quad_mask, height = 0.03, feet_height = 0.12) #5-8cm \n",
    "            \n",
    "#                         find_feet_top_success, centerX, centerY, minX, minY, maxX, maxY, feet_img = \\\n",
    "#                             _feet_detection.find_center_and_vector_by_top(feet_list, feet_img, plane_mask)\n",
    "                        \n",
    "# #                         if(find_feet_top_success):\n",
    "# #                             feet_img, px, py = \\\n",
    "# #                                 _feet_detection.find_plane_center(centerX, centerY, minX, minY, maxX, maxY, feet_img, points3D, plane_size = 0.2)\n",
    "            \n",
    "#                         if(SendData and find_feet_top_success):\n",
    "#                             _Tranform_Data.send_forward_vector(minX, minY, maxX, maxY, points3D)\n",
    "                        \n",
    "#                             feet_img, px, py = \\\n",
    "#                                 _feet_detection.find_plane_center(centerX, centerY, minX, minY, maxX, maxY, feet_img, points3D, plane_size = 0.2)\n",
    "#                             _Tranform_Data.send_targetpos(px, py, points3D)\n",
    "                            \n",
    "\n",
    "                            \n",
    "#                 #show image\n",
    "# #                 painter.paint (item_z, 'Depth')\n",
    "#                 painter.paint (grayvalue_img, 'grayvalue_img')\n",
    "# #                 painter.paint (quad_mask.astype(np.uint8)*255 , 'quad_mask')\n",
    "#                 painter.paint (feet_img, 'feet_img')\n",
    "# #                 painter.paint (height_mask_region, 'height_mask_region')\n",
    "                \n",
    "                \n",
    "#                 if(SendData):\n",
    "#                     _Tranform_Data.send_plane_eq(surface_plane)\n",
    "                    \n",
    "               "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
