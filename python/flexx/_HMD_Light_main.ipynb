{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import roypy\n",
    "import time\n",
    "import queue\n",
    "from sample_camera_info import print_camera_info\n",
    "from roypy_sample_utils import CameraOpener, add_camera_opener_options\n",
    "#from roypy_platform_utils import PlatformHelper\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import random\n",
    "import math\n",
    "from matplotlib.path import Path\n",
    "\n",
    "import socket_sender\n",
    "import _RANSAC\n",
    "import _Find_quad\n",
    "import _HMD_Light_function\n",
    "import _Tranform_Data\n",
    "import _feet_detection\n",
    "import _Record_img\n",
    "import _Feet_detection_by_center\n",
    "\n",
    "\n",
    "try:\n",
    "    import roypycy\n",
    "except ImportError:\n",
    "    print(\"Pico Flexx backend requirements (roypycy) not installed properly\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def depth_range_mask(depthImg, low, height):\n",
    "    highter_region = depthImg > low\n",
    "    lower_region = depthImg < height\n",
    "    depth_mask = np.logical_and(highter_region, lower_region)\n",
    "    \n",
    "    depth_mask_ = depth_mask.astype(np.uint8)*255\n",
    "    \n",
    "    kernel_size = 5 #7\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT,(kernel_size, kernel_size))\n",
    "    #膨胀之后再腐蚀，在用来关闭前景对象里的小洞或小黑点\n",
    "    #开运算用于移除由图像噪音形成的斑点\n",
    "    opened = cv2.morphologyEx(depth_mask_, cv2.MORPH_OPEN, kernel)\n",
    "    depth_mask_ = cv2.morphologyEx(opened,cv2.MORPH_CLOSE,kernel)\n",
    "    \n",
    "     #find Contours with largest area \n",
    "    (_, cnts, _) = cv2.findContours(depth_mask_, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    if len(cnts) > 0:\n",
    "        cnt_ = sorted(cnts, key = cv2.contourArea, reverse = True)[0]\n",
    "        \n",
    "        peri = cv2.arcLength(cnt_, True)\n",
    "        approx = cv2.approxPolyDP(cnt_, 0.03* peri, True)\n",
    "        hull = cv2.convexHull(approx)\n",
    "        \n",
    "        #mask of max contour area\n",
    "        max_area_mask = np.zeros(depthImg.shape, dtype='uint8')  #依Contours圖形建立mask\n",
    "        cv2.drawContours(max_area_mask, [hull], -1, 255, -1) #255        →白色, -1→塗滿\n",
    "        \n",
    "        #mask the depth mask with max_area_mask\n",
    "        mask = cv2.add(depth_mask_, np.zeros(np.shape(depthImg), dtype='uint8'), mask=max_area_mask)\n",
    "        \n",
    "        depth_img_with_mask = cv2.add(depthImg, np.zeros(np.shape(depthImg), dtype=np.float32), mask=mask)\n",
    "    \n",
    "    else:\n",
    "        depth_img_with_mask = cv2.add(depthImg, np.zeros(np.shape(depthImg), dtype=np.float32), mask=depth_mask_)\n",
    "        mask = depth_mask_\n",
    "    \n",
    "    \n",
    "    \n",
    "    return mask, depth_img_with_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyListener(roypy.IDepthDataListener):\n",
    "    def __init__(self, xqueue, yqueue, zqueue, grayValuequeue):\n",
    "        super(MyListener, self).__init__()\n",
    "        self.xqueue = xqueue\n",
    "        self.yqueue = yqueue\n",
    "        self.zqueue = zqueue\n",
    "        self.grayValuequeue = grayValuequeue\n",
    "        self.Listening = True\n",
    "\n",
    "    def onNewData(self, data):   \n",
    "        if(self.Listening):\n",
    "            t_time = time.time()\n",
    "            \n",
    "            xvalues = []\n",
    "            yvalues = []\n",
    "            zvalues = []\n",
    "            grayvalues = []\n",
    "            \n",
    "            values = roypycy.get_backend_data(data)\n",
    "\n",
    "            xvalues = values.x\n",
    "            yvalues = values.y\n",
    "            zvalues = values.z\n",
    "            grayvalues = values.grayValue\n",
    "\n",
    "            xarray = np.asarray(xvalues)\n",
    "            yarray = np.asarray(yvalues)\n",
    "            zarray = np.asarray(zvalues)\n",
    "            \n",
    "            \n",
    "            q_x = xarray.reshape (-1, data.width)        \n",
    "            self.xqueue.put(q_x)\n",
    "            q_y = yarray.reshape (-1, data.width)        \n",
    "            self.yqueue.put(q_y)\n",
    "            q_z = zarray.reshape (-1, data.width)        \n",
    "            self.zqueue.put(q_z)\n",
    "            \n",
    "            q_grayvalues = grayvalues.reshape (-1, data.width)        \n",
    "            self.grayValuequeue.put(q_grayvalues)\n",
    "            \n",
    "            #print('store time:', (time.time()-t_time))\n",
    "\n",
    "    def paint (self, data, name):\n",
    "        \"\"\"Called in the main thread, with data containing one of the items that was added to the\n",
    "        queue in onNewData.\n",
    "        \"\"\"\n",
    "        cv2.namedWindow(name, cv2.WINDOW_NORMAL)\n",
    "        cv2.imshow(name, data)\n",
    "        cv2.waitKey(1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main ():\n",
    "    parser = argparse.ArgumentParser (usage = __doc__)\n",
    "    add_camera_opener_options (parser)\n",
    "    parser.add_argument (\"--seconds\", type=int, default=15, help=\"duration to capture data\")\n",
    "    parser.add_argument (\"--SendData\", type=bool, default=False, help=\"SendData\")\n",
    "    parser.add_argument (\"--Project_Type\", type=int, default=0, help=\"0: Project_on_body, 1: Project_on_floor\")\n",
    "    \n",
    "    timer_show = False\n",
    "    \n",
    "    # 測試用 setting\n",
    "    _Replay = True\n",
    "    if(_Replay == True):\n",
    "#         options = parser.parse_args(args=['--rrf', 'upper_line_body.rrf','--seconds', '25', '--Project_Type', '0'])\n",
    "        # project on body: upper_line_body.rrf\n",
    "        \n",
    "        options = parser.parse_args(args=['--rrf', 'feet.rrf','--seconds', '25', '--Project_Type', '1'])\n",
    "#         options = parser.parse_args(args=['--rrf', 'feet_35fps_3.rrf','--seconds', '25', '--Project_Type', '2'])\n",
    "        # project on floor: feet_35fps.rrf  feet_35fps_2.rrf feet0221 feet\n",
    "    else:\n",
    "        options = parser.parse_args(args=['--seconds', '30', '--Project_Type', '0'])\n",
    "#         options = parser.parse_args(args=['--seconds', '30', '--Project_Type', '1'])\n",
    "#         options = parser.parse_args(args=['--seconds', '30', '--Project_Type', '2'])\n",
    "#         options = parser.parse_args(args=['--seconds', '30', '--Project_Type', '3'])\n",
    "        \n",
    "\n",
    "    opener = CameraOpener (options)\n",
    "    cam = opener.open_camera ()\n",
    "    \n",
    "    if(_Replay == False):\n",
    "        #MODE_9_5FPS_2000 MODE_5_45FPS_500 MODE_5_35FPS_600\n",
    "#         cam.setUseCase('MODE_5_45FPS_500') # body\n",
    "        cam.setUseCase('MODE_5_35FPS_600') #floor\n",
    "\n",
    "    #Print camera information\n",
    "    print_camera_info (cam)\n",
    "    print(\"isConnected\", cam.isConnected())\n",
    "    print(\"getFrameRate\", cam.getFrameRate())\n",
    "    print(\"UseCase\",cam.getCurrentUseCase())\n",
    "\n",
    "    # we will use this queue to synchronize the callback with the main\n",
    "    # thread, as drawing should happen in the main thread \n",
    "    x = queue.LifoQueue()\n",
    "    y = queue.LifoQueue()\n",
    "    z = queue.LifoQueue()\n",
    "    grayvalue = queue.LifoQueue()\n",
    "    l = MyListener(x,y,z,grayvalue)\n",
    "    cam.registerDataListener(l)\n",
    "    cam.startCapture()\n",
    "    \n",
    "    # create a loop that will run for a time (default 15 seconds)\n",
    "    process_event_queue (x, y, z, grayvalue, l, options.seconds, options.Project_Type, cam)\n",
    "    cam.stopCapture()\n",
    "    socket_sender.close_socket()\n",
    "    \n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_event_queue (x,y,z,grayvalue, painter, seconds, Project_Type, cam):\n",
    "    SendData = True\n",
    "    Record_img = False\n",
    "#     Project_Type = 0  # 0: project on body, 1: project on floor, 3: calibration shift\n",
    "\n",
    "    _Tranform_Data.send_project_type(Project_Type)\n",
    "    _Tranform_Data.send_project_type(Project_Type)\n",
    "    \n",
    "    #initial\n",
    "    last_inliner_num = 20000\n",
    "    quad_mask = np.zeros((171,224))\n",
    "    circles_image = np.zeros((171,224,3))\n",
    "    num_of_frame = 0\n",
    "    feet_mask = np.ones((171,224))\n",
    "    \n",
    "    # create a loop that will run for the given amount of time\n",
    "    print(\"  Quit : Q\\n\")\n",
    "    while 1 :\n",
    "        t_time = time.time()\n",
    "        try:\n",
    "            # try to retrieve an item from the queue.\n",
    "            # this will block until an item can be retrieved\n",
    "            # or the timeout of 1 second is hit\n",
    "            t_time = time.time()\n",
    "            \n",
    "            item_x = x.get(True, 0.5)\n",
    "            item_y = y.get(True, 0.5)\n",
    "            item_z = z.get(True, 0.5)\n",
    "            points3D = np.dstack((item_x,item_y,item_z))\n",
    "            item_grayvalue = grayvalue.get(True, 0.5)\n",
    "            #print('queue time:', (time.time()-t_time))\n",
    "        except queue.Empty:\n",
    "            # this will be thrown when the timeout is hit\n",
    "            print(\"Empty\")\n",
    "#             break\n",
    "            continue\n",
    "        else:\n",
    "            num_of_frame = num_of_frame + 1\n",
    "            \n",
    "            #turn item_grayvalue to uint8\n",
    "            grayvalue_img = cv2.convertScaleAbs(item_grayvalue)\n",
    "            \n",
    "            #if there have z value(z != 0) ==> True\n",
    "            Confidence_img = points3D[:,:,2] != 0 \n",
    "            \n",
    "            \"\"\"project on body -- 45fps\"\"\"\n",
    "            if Project_Type == 0: # project on body\n",
    "                # mask the depth image with depth range\n",
    "                depth_mask, depth_img_with_mask = depth_range_mask(item_z, 0.25, 0.6)#0.3m(30cm) 0.5m(50cm)\n",
    "\n",
    "                #turn bool img to uint8\n",
    "                depth_mask = depth_mask.astype(np.uint8)*255  \n",
    "\n",
    "                #find target plane\n",
    "                find_target_plane_success, circles_image, plane_x, plane_y, plane_points = \\\n",
    "                    _HMD_Light_function.find_target_plane(grayvalue_img, depth_mask, Confidence_img, points3D)\n",
    "\n",
    "            \n",
    "                if(SendData and find_target_plane_success):\n",
    "                    _Tranform_Data.send_target_plane(plane_points)\n",
    "                   \n",
    "\n",
    "                #show image\n",
    "                painter.paint (circles_image, 'circles_image')\n",
    "                painter.paint (Confidence_img.astype(np.uint8)*255 , 'Confidence_img')\n",
    "                \n",
    "                #Record\n",
    "                if Record_img and num_of_frame < 200:\n",
    "                    _Record_img.storeimg((grayvalue_img, circles_image), num_of_frame, 'project_on_body', string = 'body0_')\n",
    "                \n",
    "            \n",
    "            elif Project_Type == 1: #Project_on_Floor\n",
    "                \"\"\"project on Floor\"\"\"\n",
    "                #find plane by RANSAC\n",
    "                surface_plane, depthImg, plane_mask, best_sampts, best_inlinernum = \\\n",
    "                _RANSAC.RANSAM(points3D, Confidence_img, ransac_iteration = 50, inliner_threshold = 0.01, last_inliner_num = last_inliner_num)#1cm  0.003\n",
    "                last_inliner_num = best_inlinernum\n",
    "                \n",
    "                #turn bool img to uint8\n",
    "                plane_img = plane_mask.astype(np.uint8)*255 \n",
    "                \n",
    "                #find large 四邊形 on the mask of plane, and find the center of it\n",
    "                find_quad_success, find_quad_img, approx, cx, cy = _Find_quad.find_quadrilateral(plane_img)\n",
    "                \n",
    "                if find_quad_success:\n",
    "                    # Get the quad_mask\n",
    "                    mask_success, quad_mask = _Find_quad.find_quad_mask(approx, plane_img.shape)\n",
    "                    if mask_success:\n",
    "                        #Confi_mask : 去掉雜訊多的區域\n",
    "                        Confi_mask = np.zeros((171,224), np.uint8)\n",
    "                        cv2.circle(Confi_mask, (Confi_mask.shape[1]//2,Confi_mask.shape[0]//2), 110, 255 , -1)\n",
    "                        \n",
    "                        ###### v1.2 \n",
    "#                         feet_img, height_mask_region, new_feet_mask, f_mask, feet_top, Non_VR_feet_top = \\\n",
    "#                             _Feet_detection_by_center.feet_detection(depthImg, quad_mask, feet_mask, Confi_mask, height = 0.03, feet_height = 0.10)\n",
    "                        \n",
    "#                         if new_feet_mask:\n",
    "#                             feet_mask = f_mask\n",
    "                        ###### v1.2 \n",
    "                        \n",
    "                        ###### v1.3\n",
    "                        top_line = _Feet_detection_by_center.get_feet_detection_line(surface_plane)\n",
    "                        feet_image, VR_feet_region, VR_feet_center, Non_VR_region, Non_VR_feet_top = \\\n",
    "                            _Feet_detection_by_center.feet_detection_with_line(depthImg, quad_mask, Confi_mask, top_line, height = 0.03, feet_height = 0.10)\n",
    "                        ###### v1.3\n",
    "                        \n",
    "                        find_feet_top_success, centerX, centerY, minX, minY, maxX, maxY, feet_img = \\\n",
    "                            _Feet_detection_by_center.find_center_and_vector_by_top(VR_feet_center, feet_image)\n",
    "                        \n",
    "                        if(find_feet_top_success):\n",
    "                            center_success, feet_img, px, py = _Feet_detection_by_center.find_plane_center\\\n",
    "                                                    (centerX, centerY, minX, minY, maxX, maxY, feet_img, points3D, plane_mask, plane_size = 0.4)\n",
    "            \n",
    "                        if(SendData and find_feet_top_success):\n",
    "                            _Tranform_Data.send_forward_vector(minX, minY, maxX, maxY, points3D)\n",
    "        \n",
    "                            if center_success:\n",
    "                                _Tranform_Data.send_targetpos(px, py, points3D)\n",
    "                                   \n",
    "                #show image\n",
    "                painter.paint (grayvalue_img, 'grayvalue_img')\n",
    "                painter.paint (feet_img, 'feet_img')\n",
    "#                 painter.paint (depthImg, 'Depth')\n",
    "#                 painter.paint (feet_mask.astype(np.uint8)*255 , 'feet_mask')\n",
    "#                 painter.paint (height_mask_region, 'height_mask_region')\n",
    "\n",
    "#                 painter.paint (VR_feet_region, 'VR_feet_region')\n",
    "#                 painter.paint (feet_image, 'feet_image')\n",
    "                \n",
    "#                 painter.paint (Confi_mask.astype(np.uint8), 'Confi_mask')\n",
    "#                 painter.paint (quad_mask.astype(np.uint8)*255, 'quad_mask')\n",
    "#                 painter.paint (np.logical_and(Confi_mask,quad_mask).astype(np.uint8)*255, 'mask')\n",
    "                \n",
    "                #Record\n",
    "                if Record_img and num_of_frame > 60 and num_of_frame < 360:\n",
    "                     _Record_img.storeimg((grayvalue_img,height_mask_region,feet_img), num_of_frame, 'project_on_floor',string = 'floor1_')\n",
    "                \n",
    "                if(SendData):\n",
    "                    _Tranform_Data.send_plane_eq(surface_plane)\n",
    "       \n",
    "            elif Project_Type == 3: #Calibration => 調整 lenshift\n",
    "                \"\"\"Calibration\"\"\" \n",
    "                #find plane by RANSAC\n",
    "                surface_plane, depthImg, plane_mask, best_sampts, best_inlinernum = \\\n",
    "                _RANSAC.RANSAM(points3D, Confidence_img, ransac_iteration = 50, inliner_threshold = 0.01, last_inliner_num = last_inliner_num)#1cm  0.003\n",
    "                last_inliner_num = best_inlinernum\n",
    "                \n",
    "                #turn bool img to uint8\n",
    "                plane_img = plane_mask.astype(np.uint8)*255 \n",
    "                \n",
    "                #find large 四邊形 on the mask of plane, and find the center of it\n",
    "                find_quad_success, find_quad_img, approx, cx, cy = _Find_quad.find_quadrilateral(plane_img)\n",
    "                \n",
    "                if find_quad_success:\n",
    "                    # Get the quad_mask\n",
    "                    mask_success, quad_mask = _Find_quad.find_quad_mask(approx, plane_img.shape)\n",
    "                    if mask_success:\n",
    "                        #find target circle\n",
    "                        find_target_success, px, py, circles_image = _HMD_Light_function.find_target_circle(grayvalue_img, quad_mask, plane_mask)\n",
    "            \n",
    "                        if(SendData and find_target_success):\n",
    "                            _Tranform_Data.send_targetpos(px, py, points3D)\n",
    "                            \n",
    "                            vx, vy = _HMD_Light_function.find_plane_forward_vector(px, approx, plane_mask, 30)\n",
    "                            _Tranform_Data.send_forward_vector(px, py, vx, vy, points3D)\n",
    "                            \n",
    "        \n",
    "                #show image\n",
    "                painter.paint (circles_image, 'circles_image')\n",
    "                \n",
    "                \n",
    "                if(SendData):\n",
    "                    _Tranform_Data.send_plane_eq(surface_plane)\n",
    "                        \n",
    "        \n",
    "                \n",
    "            else: \n",
    "                break\n",
    "        \n",
    "#         print('time:', (time.time()-t_time))\n",
    "        \n",
    "        if(cv2.waitKey(10) & 0xFF == 113):#耗時0.01s\n",
    "            break\n",
    "\n",
    "        if(SendData):\n",
    "            stop, Type = _Tranform_Data.receive_data(cam)\n",
    "            if Type != -1:\n",
    "                Project_Type = Type\n",
    "            if stop:\n",
    "                break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filename: upper_line_body.rrf\n",
      "====================================\n",
      "        Camera information\n",
      "====================================\n",
      "Type:            PICOFLEXX\n",
      "Width:           224\n",
      "Height:          171\n",
      "Operation modes: 1\n",
      "    MODE_PLAYBACK\n",
      "        this operation mode has 451670832 streams\n",
      "Lens parameters: 9\n",
      "    ('cx', 118.28559112548828)\n",
      "    ('cy', 87.74105072021484)\n",
      "    ('fx', 213.8031768798828)\n",
      "    ('fy', 213.8031768798828)\n",
      "    ('k1', 0.4155448377132416)\n",
      "    ('k2', -4.7316107749938965)\n",
      "    ('k3', 8.45906925201416)\n",
      "    ('p1', 7.605663946304829e-16)\n",
      "    ('p2', 4.939198934392371e-16)\n",
      "CameraInfo items: 0\n",
      "isConnected True\n",
      "getFrameRate 0\n",
      "UseCase MODE_PLAYBACK\n",
      "create socket successful\n",
      "  Quit : Q\n",
      "\n",
      "Empty\n",
      "Empty\n",
      "Empty\n",
      "receive 2 stop!\n",
      "close the socket successful\n",
      "close the socket successful\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "close the socket successful\n"
     ]
    }
   ],
   "source": [
    "socket_sender.close_socket()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cam.stopCapture()\n",
    "# socket_sender.close_socket()\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !jupyter nbconvert --to script _HMD_Light_main.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#project on body 20200218\n",
    "\n",
    "#                 #find single targetline\n",
    "#                 find_target_success, circles_image, px, py, minX, minY, maxX, maxY = \\\n",
    "#                                 _HMD_Light_function.find_targetLine_pos(grayvalue_img, depth_mask, Confidence_img)\n",
    "                \n",
    "                    #show target points in 3d image        \n",
    "#                 _HMD_Light_function.show_plqane(plane_x, plane_y, points3D)\n",
    "\n",
    "# send data\n",
    " # #                    find the 3d point for reprojected u v \n",
    "#                     _Tranform_Data.send_target_plane(plane_x, plane_y, points3D)               \n",
    "#                     for single targetline\n",
    "#                     _Tranform_Data.send_targetpos(px, py, points3D)\n",
    "#                     _Tranform_Data.send_forward_vector(minX, minY, maxX, maxY, points3D)\n",
    "\n",
    "# show image\n",
    "#                 painter.paint (item_z, 'Depth')\n",
    "#                 painter.paint (depth_img_with_mask, 'depth_img_with_mask')\n",
    "#                 painter.paint (grayvalue_img, 'grayvalue_img')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#project on floor 20200213\n",
    " #                find target circle\n",
    "#                         find_target_success, px, py, circles_image = _HMD_Light_function.find_target_circle(grayvalue_img, quad_mask, plane_mask)\n",
    "                        \n",
    "#                         #find single targetline\n",
    "# #                         find_target_success, circles_image, px, py, minX, minY, maxX, maxY = \\\n",
    "# #                                 _HMD_Light_function.find_targetLine_pos(grayvalue_img, quad_mask, plane_mask)\n",
    "                        \n",
    "#                         #find line => not good result\n",
    "# #                         line_image = _HMD_Light_function.find_line(grayvalue_img, quad_mask)\n",
    "\n",
    "\n",
    "\n",
    "#                         if(SendData and find_target_success):\n",
    "#                             _Tranform_Data.send_targetpos(px, py, points3D)\n",
    "                            \n",
    "#                             vx, vy = _HMD_Light_function.find_plane_forward_vector(px, approx, plane_mask, 30)\n",
    "#                             _Tranform_Data.send_forward_vector(px, py, vx, vy, points3D)\n",
    "\n",
    "# #                             _Tranform_Data.send_forward_vector(minX, minY, maxX, maxY, points3D)\n",
    "                            \n",
    "#                             # 2個send中要有延遲(show image 或 print)才不會卡\n",
    "# #                             print(\"1\") \n",
    "\n",
    "\n",
    "# if(SendData):\n",
    "#                     _Tranform_Data.send_plane_eq(surface_plane)\n",
    "\n",
    "\n",
    "#20200225 Feet detection\n",
    "                         ###### v1.2\n",
    "#                         feet_img, height_mask_region, feet_top = \\\n",
    "#                             _Feet_detection_by_center.feet_center_detection(depthImg, quad_mask, Confi_mask, height = 0.03, feet_height = 0.10, VR_user = True)\n",
    "                        ###### v1.2\n",
    "                        ###### v1.0 fit ellipse\n",
    "#                         feet_img, height_mask_region, ellipse_list, feet_top = \\\n",
    "#                             _feet_detection.feet_top_detection(depthImg, quad_mask, height = 0.05, feet_height = 0.10, VR_user = True) #5-8cm \n",
    "                        ###### v1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mask = np.zeros((171,224), np.uint8)\n",
    "# cv2.circle(mask, (mask.shape[1]//2,mask.shape[0]//2), 110, 255 , -1)\n",
    "# plt.imshow(mask.astype(np.uint8)*255)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !jupyter nbconvert --to script _HMD_Light_main.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "                    \n",
    "#             elif Project_Type == 2: #Project_on_Floor go forward\n",
    "#                 \"\"\"project on Floor go forward\"\"\"\n",
    "#                 #find plane by RANSAC\n",
    "#                 surface_plane, depthImg, plane_mask, best_sampts, best_inlinernum = \\\n",
    "#                 _RANSAC.RANSAM(points3D, Confidence_img, ransac_iteration = 50, inliner_threshold = 0.02, last_inliner_num = last_inliner_num)#1cm  0.003\n",
    "#                 last_inliner_num = best_inlinernum\n",
    "                \n",
    "#                 #turn bool img to uint8\n",
    "#                 plane_img = plane_mask.astype(np.uint8)*255 \n",
    "                \n",
    "#                 #find large 四邊形 on the mask of plane, and find the center of it\n",
    "#                 find_quad_success, find_quad_img, approx, cx, cy = _Find_quad.find_quadrilateral(plane_img)\n",
    "                \n",
    "#                 if find_quad_success:\n",
    "#                     # Get the quad_mask\n",
    "#                     mask_success, quad_mask = _Find_quad.find_quad_mask(approx, plane_img.shape)\n",
    "#                     if mask_success:\n",
    "#                         feet_img, height_mask_region, ellipse_list, feet_list = \\\n",
    "#                             _feet_detection.feet_list_detection(depthImg, quad_mask, height = 0.03, feet_height = 0.12) #5-8cm \n",
    "            \n",
    "#                         find_feet_top_success, centerX, centerY, minX, minY, maxX, maxY, feet_img = \\\n",
    "#                             _feet_detection.find_center_and_vector_by_top(feet_list, feet_img, plane_mask)\n",
    "                        \n",
    "# #                         if(find_feet_top_success):\n",
    "# #                             feet_img, px, py = \\\n",
    "# #                                 _feet_detection.find_plane_center(centerX, centerY, minX, minY, maxX, maxY, feet_img, points3D, plane_size = 0.2)\n",
    "            \n",
    "#                         if(SendData and find_feet_top_success):\n",
    "#                             _Tranform_Data.send_forward_vector(minX, minY, maxX, maxY, points3D)\n",
    "                        \n",
    "#                             feet_img, px, py = \\\n",
    "#                                 _feet_detection.find_plane_center(centerX, centerY, minX, minY, maxX, maxY, feet_img, points3D, plane_size = 0.2)\n",
    "#                             _Tranform_Data.send_targetpos(px, py, points3D)\n",
    "                            \n",
    "\n",
    "                            \n",
    "#                 #show image\n",
    "# #                 painter.paint (item_z, 'Depth')\n",
    "#                 painter.paint (grayvalue_img, 'grayvalue_img')\n",
    "# #                 painter.paint (quad_mask.astype(np.uint8)*255 , 'quad_mask')\n",
    "#                 painter.paint (feet_img, 'feet_img')\n",
    "# #                 painter.paint (height_mask_region, 'height_mask_region')\n",
    "                \n",
    "                \n",
    "#                 if(SendData):\n",
    "#                     _Tranform_Data.send_plane_eq(surface_plane)\n",
    "                    \n",
    "               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
